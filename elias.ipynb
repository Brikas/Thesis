{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import brikasutils as bu\n",
    "importlib.reload(bu)\n",
    "import fb_msg_reader as fb\n",
    "importlib.reload(fb)\n",
    "import shared_utils as utils\n",
    "importlib.reload(utils)\n",
    "import survey\n",
    "importlib.reload(survey)\n",
    "import persona\n",
    "importlib.reload(persona)\n",
    "\n",
    "import ollama\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 1916 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-09-13 to 2024-03-06\n",
      "Messages saved to self.chats['airidas']\n",
      "Read 618 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-09-10 to 2024-03-03\n",
      "Messages saved to self.chats['christian']\n",
      "Read 297 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2018-07-25 to 2024-01-01\n",
      "Messages saved to self.chats['nikolay']\n",
      "Read 144 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-03-28 to 2021-12-30\n",
      "Messages saved to self.chats['mathis']\n",
      "Read 104 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-08-25 to 2024-03-05\n",
      "Messages saved to self.chats['jacob']\n",
      "Read 159 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-10-12 to 2023-04-30\n",
      "Messages saved to self.chats['chris']\n",
      "Read 161 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-03-28 to 2021-06-06\n",
      "Messages saved to self.chats['aziz']\n",
      "Read 350 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-03-26 to 2022-04-11\n",
      "Messages saved to self.chats['daniela']\n",
      "Read 105 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-03-28 to 2022-07-10\n",
      "Messages saved to self.chats['mihi']\n",
      "Read 117 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-05-17 to 2022-04-11\n",
      "Messages saved to self.chats['viktoria']\n",
      "Read 172 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2019-08-11 to 2023-12-21\n",
      "Messages saved to self.chats['diba']\n",
      "Read 154 messages from 1 files. Failed to read 0 messages.\n",
      "Messages ranged from 2021-12-02 to 2023-04-29\n",
      "Messages saved to self.chats['filip']\n",
      "Filtering\n",
      "link-filter: 109\n",
      "react-filter: 0\n",
      "cookie-data-filter: 12\n",
      "Selected chat airidas for 9995 (668 messages)\n",
      "Selected chat christian for 5252 (576 messages)\n",
      "Selected chat nikolay for 3128 (266 messages)\n",
      "Selected chat mathis for 1325 (134 messages)\n",
      "Selected chat daniela for 2881 (293 messages)\n",
      "Selected chat diba for 1799 (156 messages)\n",
      "Selected chat aziz for 1219 (136 messages)\n",
      "Selected chat jacob for 1124 (93 messages)\n",
      "Selected chat chris for 1535 (151 messages)\n",
      "Selected chat filip for 1306 (146 messages)\n",
      "Selected chat mihi for 1098 (102 messages)\n",
      "Selected chat viktoria for 1168 (107 messages)\n",
      "Combined tokens: 31830\n"
     ]
    }
   ],
   "source": [
    "et = persona.PersonaEncoder()\n",
    "\n",
    "# ==== FB messages ====\n",
    "et.parse_fb_messages([\"data-raw/1_airidas.json\"], \"airidas\")\n",
    "et.parse_fb_messages([\"data-raw/2_christian.json\"], \"christian\")\n",
    "et.parse_fb_messages([\"data-raw/1_nikolay.json\"], \"nikolay\")\n",
    "et.parse_fb_messages([\"data-raw/2_mathis.json\"], \"mathis\")\n",
    "et.parse_fb_messages([\"data-raw/2_jacob.json\"], \"jacob\")\n",
    "et.parse_fb_messages([\"data-raw/2_chris.json\"], \"chris\")\n",
    "et.parse_fb_messages([\"data-raw/3_aziz.json\"], \"aziz\")\n",
    "et.parse_fb_messages([\"data-raw/3_daniela.json\"], \"daniela\")\n",
    "et.parse_fb_messages([\"data-raw/3_mihi.json\"], \"mihi\")\n",
    "et.parse_fb_messages([\"data-raw/3_viktoria.json\"], \"viktoria\")\n",
    "et.parse_fb_messages([\"data-raw/4_diba.json\"], \"diba\")\n",
    "et.parse_fb_messages([\"data-raw/6_filip.json\"], \"filip\")\n",
    "#et.parse_wa_messages(texts_with_rebecca, \"rebecca\")\n",
    "# texts_with_others_dict = {\n",
    "#     \"rebecca\": [\"data-raw/messages_1000.json\"],\n",
    "# }\n",
    "# for name, texts in texts_with_others_dict.items():\n",
    "#     et.parse_fb_messages(texts, name)\n",
    "\n",
    "# Regex cleaning\n",
    "et.filter_chats_empty()\n",
    "et.filter_chats_regex(utils.BLACKLIST_CHAT_REGEX_FILTERS)\n",
    "\n",
    "# Compress names\n",
    "for nameid, chat in et.chats.items():\n",
    "    for msg in chat:  \n",
    "        msg.sender = \"Persona\" if msg.sender == \"Elias Salvador Smidt Torjani\"  else \"Friend\"\n",
    "\n",
    "# Start all chats from 2/3rds\n",
    "# for name, chat in et.chats.items():\n",
    "#     et.chats[name] = chat[int(len(chat)/3 * 2):]\n",
    "# Select the final modules\n",
    "et.select_chat_limited_by_tokens(\"airidas\", 10000)\n",
    "et.select_chat_limited_by_tokens(\"christian\", 10000)\n",
    "et.select_chat_full(\"nikolay\")\n",
    "et.select_chat_full(\"mathis\") \n",
    "et.select_chat_full(\"daniela\")\n",
    "et.select_chat_full(\"diba\")\n",
    "et.select_chat_full(\"aziz\")\n",
    "et.select_chat_full(\"jacob\")  \n",
    "et.select_chat_full(\"chris\")\n",
    "et.select_chat_full(\"filip\")\n",
    "et.select_chat_full(\"mihi\")\n",
    "et.select_chat_full(\"viktoria\")\n",
    "# for name in texts_with_others_dict.keys():\n",
    "#     ab.select_chat_full(name)\n",
    "\n",
    "# save\n",
    "big_module=et.output()\n",
    "bu.quickTXT(big_module, filename=f\"data/big_module_{bu.get_timestamp()}\")\n",
    "\n",
    "# stats\n",
    "token_counts = et.count_all_selected_chat_tokens() # token_counts used later for statistics\n",
    "print(f\"Combined tokens: {sum(token_counts.values())}\")\n",
    "# utils.count_tokens(big_module) \n",
    "# or list(et.selectedChats.keys()) --> et.count_chat_tokens(\"{friend}\")\n",
    "# et.selectedChats[\"{friend}\"][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default Personality Survey CSV file: surveys/survey_personality-test.csv\n"
     ]
    }
   ],
   "source": [
    "surv = survey.PersonalitySurvey()\n",
    "# surv = survey.KanoSurvey()\n",
    "# surv = survey.buildFairnessPrompts()\n",
    "# surv = survey.DictatorGameSurvey()\n",
    "\n",
    "surv.questions[:2]#.head()\n",
    "\n",
    "# Change below accoring to survey above\n",
    "RETRIEVAL_PROMPT = \"openess conciousness extrovert aggreableness neuroticism\" #\"personality\"\n",
    "# q_retrival_prompt =\n",
    "SURVEY_PROMPT = \"Determine how much {subject} aggree with the statement. Guestimate how {subject} would answer to the question\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS\n",
    "EMBED_MODEL = \"nomic-embed-text\"        # nomic-embed-text = long ctx / mxbai-embed-large = big\n",
    "CHUNK_SIZE = 30                         # Number of messages per chunk\n",
    "OVERLAP_SIZE = 10                       # Number of overlapping messages between consecutive chunks\n",
    "CHUNKS_COUNT_IN_CTX = 30 # Number of nearby chunks to put in context window\n",
    "# COMMENT 04-16, perhaps we could try 5x retrievals with isolated semantics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk count: 130\n",
      "Average chunk character length: 1244\n",
      "Rough estimate of tokens per chunk: 311 (4 characters per token)\n",
      "Messagees in input count: 2828\n",
      "Messages in chunks count: 3900\n",
      "Chunk \\ Input ratio: 1.38 (OVERLAP_SIZE=10)\n",
      "Chunk Python type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists for storing chunks â€“ and embeddings later\n",
    "# different chunk size\n",
    "chunks = []\n",
    "stat_total_msgs_in_chunks = 0 # for statistics\n",
    "\n",
    "# different chunk size\n",
    "# Iterate over chats and messages to create chunks\n",
    "for chat in et.selectedChats.values():\n",
    "    messages = list(chat)  # Convert chat iterator to list for easier slicing\n",
    "    num_messages = len(messages)\n",
    "\n",
    "    # Create overlapping chunks of messages\n",
    "    for i in range(0, num_messages - CHUNK_SIZE + 1, CHUNK_SIZE - OVERLAP_SIZE):\n",
    "        chunk = messages[i:i + CHUNK_SIZE]  # Extract chunk of messages\n",
    "        chunk_text = \"\\n\".join(str(msg) for msg in chunk)  # Concatenate messages into a single string\n",
    "        chunks.append(chunk_text)  # Append chunk to list of chunks\n",
    "\n",
    "        stat_total_msgs_in_chunks += len(chunk) # For statistics\n",
    "\n",
    "##### Display Info\n",
    "total_messages = sum(len(chat) for chat in et.selectedChats.values())\n",
    "chunks_count = len(chunks)\n",
    "avg_chunk_char_len = np.mean([len(chunk) for chunk in chunks])\n",
    "\n",
    "print(\n",
    "    f\"Chunk count: {chunks_count}\",\n",
    "    f\"Average chunk character length: {round( avg_chunk_char_len)}\",\n",
    "    f\"Rough estimate of tokens per chunk: {round(avg_chunk_char_len / 4)} (4 characters per token)\",\n",
    "    f\"Messagees in input count: {total_messages}\",\n",
    "    f\"Messages in chunks count: {stat_total_msgs_in_chunks}\",\n",
    "    f\"Chunk \\ Input ratio: {round(stat_total_msgs_in_chunks / total_messages,2)} (OVERLAP_SIZE={OVERLAP_SIZE})\",\n",
    "    f\"Chunk Python type: {type(chunks[0])}\",\n",
    "    sep=\"\\n\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Serialization ########\n",
    "EMBEDDING_NAMEID = \"test03\"\n",
    "AUTO_INFO = {\n",
    "    \"model\": EMBED_MODEL,\n",
    "    \"CHUNK_SIZE\": CHUNK_SIZE,\n",
    "    \"OVERLAP_SIZE\": OVERLAP_SIZE,\n",
    "    \"chunks_count\": chunks_count,\n",
    "    \"total_messages\": total_messages,\n",
    "    \"stat_total_msgs_in_chunks\": stat_total_msgs_in_chunks,\n",
    "    \"modules_chat\": token_counts,\n",
    "}\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk 1/130\n",
      "Chunk 2/130\n",
      "Chunk 3/130\n",
      "Chunk 4/130\n",
      "Chunk 5/130\n",
      "Chunk 6/130\n",
      "Chunk 7/130\n",
      "Chunk 8/130\n",
      "Chunk 9/130\n",
      "Chunk 10/130\n",
      "Chunk 11/130\n",
      "Chunk 12/130\n",
      "Chunk 13/130\n",
      "Chunk 14/130\n",
      "Chunk 15/130\n",
      "Chunk 16/130\n",
      "Chunk 17/130\n",
      "Chunk 18/130\n",
      "Chunk 19/130\n",
      "Chunk 20/130\n",
      "Chunk 21/130\n",
      "Chunk 22/130\n",
      "Chunk 23/130\n",
      "Chunk 24/130\n",
      "Chunk 25/130\n",
      "Chunk 26/130\n",
      "Chunk 27/130\n",
      "Chunk 28/130\n",
      "Chunk 29/130\n",
      "Chunk 30/130\n",
      "Chunk 31/130\n",
      "Chunk 32/130\n",
      "Chunk 33/130\n",
      "Chunk 34/130\n",
      "Chunk 35/130\n",
      "Chunk 36/130\n",
      "Chunk 37/130\n",
      "Chunk 38/130\n",
      "Chunk 39/130\n",
      "Chunk 40/130\n",
      "Chunk 41/130\n",
      "Chunk 42/130\n",
      "Chunk 43/130\n",
      "Chunk 44/130\n",
      "Chunk 45/130\n",
      "Chunk 46/130\n",
      "Chunk 47/130\n",
      "Chunk 48/130\n",
      "Chunk 49/130\n",
      "Chunk 50/130\n",
      "Chunk 51/130\n",
      "Chunk 52/130\n",
      "Chunk 53/130\n",
      "Chunk 54/130\n",
      "Chunk 55/130\n",
      "Chunk 56/130\n",
      "Chunk 57/130\n",
      "Chunk 58/130\n",
      "Chunk 59/130\n",
      "Chunk 60/130\n",
      "Chunk 61/130\n",
      "Chunk 62/130\n",
      "Chunk 63/130\n",
      "Chunk 64/130\n",
      "Chunk 65/130\n",
      "Chunk 66/130\n",
      "Chunk 67/130\n",
      "Chunk 68/130\n",
      "Chunk 69/130\n",
      "Chunk 70/130\n",
      "Chunk 71/130\n",
      "Chunk 72/130\n",
      "Chunk 73/130\n",
      "Chunk 74/130\n",
      "Chunk 75/130\n",
      "Chunk 76/130\n",
      "Chunk 77/130\n",
      "Chunk 78/130\n",
      "Chunk 79/130\n",
      "Chunk 80/130\n",
      "Chunk 81/130\n",
      "Chunk 82/130\n",
      "Chunk 83/130\n",
      "Chunk 84/130\n",
      "Chunk 85/130\n",
      "Chunk 86/130\n",
      "Chunk 87/130\n",
      "Chunk 88/130\n",
      "Chunk 89/130\n",
      "Chunk 90/130\n",
      "Chunk 91/130\n",
      "Chunk 92/130\n",
      "Chunk 93/130\n",
      "Chunk 94/130\n",
      "Chunk 95/130\n",
      "Chunk 96/130\n",
      "Chunk 97/130\n",
      "Chunk 98/130\n",
      "Chunk 99/130\n",
      "Chunk 100/130\n",
      "Chunk 101/130\n",
      "Chunk 102/130\n",
      "Chunk 103/130\n",
      "Chunk 104/130\n",
      "Chunk 105/130\n",
      "Chunk 106/130\n",
      "Chunk 107/130\n",
      "Chunk 108/130\n",
      "Chunk 109/130\n",
      "Chunk 110/130\n",
      "Chunk 111/130\n",
      "Chunk 112/130\n",
      "Chunk 113/130\n",
      "Chunk 114/130\n",
      "Chunk 115/130\n",
      "Chunk 116/130\n",
      "Chunk 117/130\n",
      "Chunk 118/130\n",
      "Chunk 119/130\n",
      "Chunk 120/130\n",
      "Chunk 121/130\n",
      "Chunk 122/130\n",
      "Chunk 123/130\n",
      "Chunk 124/130\n",
      "Chunk 125/130\n",
      "Chunk 126/130\n",
      "Chunk 127/130\n",
      "Chunk 128/130\n",
      "Chunk 129/130\n",
      "Chunk 130/130\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chunks_most_similar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 21\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m####################################################\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Generate embeddings for each chunk\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# for chunk_text in chunks:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# token counts in all similar chunks\u001b[39;00m\n\u001b[1;32m     20\u001b[0m tokens_in_chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43mchunks_most_similar\u001b[49m:\n\u001b[1;32m     22\u001b[0m     tokens_in_chunks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mcount_tokens(chunk)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTokens in chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtokens_in_chunks\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chunks_most_similar' is not defined"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each chunk\n",
    "embeddings = []\n",
    "\n",
    "progress, chunks_len = 0, len(chunks) # for progress bar\n",
    "for chunk_text in chunks:\n",
    "    progress += 1\n",
    "    print(f\"Chunk {progress}/{chunks_len}\")\n",
    "\n",
    "    embedding = ollama.embeddings(model=EMBED_MODEL, prompt=chunk_text)[\"embedding\"]\n",
    "    embeddings.append(embedding)\n",
    "\n",
    "####################################################\n",
    "# Generate embeddings for each chunk\n",
    "# for chunk_text in chunks:\n",
    "#     embedding = ollama.embeddings(model=EMBED_MODEL, prompt=chunk_text)[\"embedding\"]\n",
    "#     embeddings.append(embedding)\n",
    "\n",
    "\n",
    "# token counts in all similar chunks\n",
    "tokens_in_chunks = 0\n",
    "for chunk in chunks_most_similar:\n",
    "    tokens_in_chunks += utils.count_tokens(chunk)\n",
    "print(f\"Tokens in chunks: {tokens_in_chunks}\")\n",
    "\n",
    "bu.quickTXT(\"\\n\\n\".join(chunks_most_similar), filename=\"data-prep/chunks.txt\")\n",
    "\n",
    "# Perform similarity search and print results\n",
    "prompt_embedding = ollama.embeddings(model=EMBED_MODEL, prompt=RETRIEVAL_PROMPT)[\"embedding\"]\n",
    "most_similar_chunks = embed.find_most_similar(prompt_embedding, embeddings)[:CHUNKS_COUNT_IN_CTX]\n",
    "chunks_most_similar = []\n",
    "for embedding in chunks_most_similar_embeddings:\n",
    "    chunks_most_similar.append(chunks[embedding[1]])\n",
    "\n",
    "# Display results\n",
    "print(f\"Chunks:{len(chunks)}, embeds:{len(embeddings)}, nearby_chunks:{len(most_similar_chunks)}\")\n",
    "for item in most_similar_chunks:\n",
    "    print(chunks[item[1]])\n",
    "####################################################\n",
    "\n",
    "# Display and save results (if needed later)\n",
    "print(f\"Chunks:{len(chunks)}, embeds:{len(embeddings)}\")\n",
    "\n",
    "bu.if_dir_not_exist_make(\"embeddings\")\n",
    "bu.quickJSON(AUTO_INFO, f\"embeddings/{EMBEDDING_NAMEID}_info.json\")\n",
    "bu.quickJSON({\"chunks\": chunks, \"embeddings\": embeddings}, f\"embeddings/{EMBEDDING_NAMEID}_embeddings.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"embeddings/{EMBEDDING_NAMEID}_embeddings.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    chunks = data[\"chunks\"]\n",
    "    embeddings = data[\"embeddings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### shit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "for item in embed.find_most_similar:\n",
    "    print(chunks[item[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################\n",
    "\n",
    "#1.0 of above smth further above\n",
    "paragraphs = []\n",
    "for chat in elias.selectedChats.values():\n",
    "    for msg in chat:\n",
    "        if msg.sender == \"Persona\":\n",
    "            paragraphs.append(str(msg))\n",
    "        \n",
    "embeddings = [\n",
    "    ollama.embeddings(model=embed, prompt=chunk)[\"embedding\"] for chunk in paragraphs\n",
    "]\n",
    "\n",
    "prompt_embedding = ollama.embeddings(model=embed, prompt=retrieval_prompt)[\"embedding\"]\n",
    "most_similar_chunks = find_most_similar(prompt_embedding, embeddings)[:5]\n",
    "\n",
    "print(f\"Paragraphs:{len(paragraphs)}, embeds:{len(embeddings)}, nearby_chunks:{len(most_similar_chunks)}\")\n",
    "print(\"\\n\".join(paragraphs[item[1]] for item in most_similar_chunks))\n",
    "#print(f\"{most_similar_chunks[0][1]}, {most_similar_chunks[:3]}\\n{len(paragraphs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = {\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"You are an actor specializing in impersonating non-famouns people. You will be presented to the subject through explicit datapoints of their digital footprint. In addition, you will deduct their implicit personality traits by shadowing chats between the subject and friends. You will be asked to answer questions from the point of view of the persona. The persona you will be impersonating is named Elias. Context:\"\n",
    "    }\n",
    "\n",
    "# persona_small = \"{small module}\"\n",
    "# persona_med = \"{med module}\"\n",
    "# persona_text = \"Favorite video games are Rimworld, Minecraft, Age of Empires, 7 Days to Die\"\n",
    "subject = elias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "final_prompts = []\n",
    "\n",
    "for question in surv.questions:\n",
    "    p = [\n",
    "        pc.systemMsg(PROMPT['content']+\"\\n## chat conversions between subject and friends\\n\".join(chunks[item[1]] for item in most_similar_chunks)),\n",
    "        pc.assistantMsg('Understood. I will answer from the point of view of the persona, {subject}, based on what I could the deduct from the text provided above.'),\n",
    "        pc.userMsg(\"\\n\".join([\n",
    "            f'\\n\\n**Your answer should only contain the chosen option without further explanation!** Reply to the statement below - how {subject} would reply - with one of these five options: {\", \".join(surv.POSSIBLE_ANSWERS)}.',\n",
    "            question\n",
    "        ])),\n",
    "    ]\n",
    "    final_prompts.append(p)\n",
    "\n",
    "print(f\"{len(final_prompts)}\")#,{final_prompts[:1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 50 prompts.\n",
      "Average prompt size: 11388 tokens.\n",
      "Min prompt size: 11385, Max prompt size: 11393\n"
     ]
    }
   ],
   "source": [
    "# Report prompt tokens\n",
    "total_all_prompt_tokens = 0\n",
    "prompt_tokens_min = 0\n",
    "prompt_tokens_max = 0\n",
    "for p in final_prompts:\n",
    "    pt = 0 # Prompt tokens\n",
    "    for msg in p:\n",
    "        pt += utils.count_tokens(msg[\"content\"])\n",
    "    if prompt_tokens_min == 0 or pt < prompt_tokens_min:\n",
    "        prompt_tokens_min = pt\n",
    "    if pt > prompt_tokens_max:\n",
    "        prompt_tokens_max = pt\n",
    "\n",
    "    total_all_prompt_tokens += pt\n",
    "\n",
    "print(f\"Created {len(final_prompts)} prompts.\")\n",
    "print(f\"Average prompt size: {round(total_all_prompt_tokens/len(final_prompts))} tokens.\")\n",
    "print(f\"Min prompt size: {prompt_tokens_min}, Max prompt size: {prompt_tokens_max}\")\n",
    "\n",
    "bu.quickJSON(final_prompts, \"data-prep/prompts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Simulation\n",
    "##################################\n",
    "SIM_ID = f\"elias_personality_03\"\n",
    "LIMIT = 10 # For testing purposes. Set to NONE to run all\n",
    "AUTO_INFO = {\n",
    "    \"date\": bu.get_timestamp(),\n",
    "    \"EMBEDDING_NAMEID\": EMBEDDING_NAMEID,\n",
    "    \"RETRIEVAL_PROMPT\": RETRIEVAL_PROMPT,\n",
    "    \"CHUNKS_COUNT_IN_CTX\": CHUNKS_COUNT_IN_CTX,\n",
    "    \"survey_type\": str(type(surv)),\n",
    "    \"prompt_count\": min(len(final_prompts), LIMIT) if LIMIT != None else len(final_prompts),\n",
    "}\n",
    "\n",
    "SETTINGS = {\n",
    "     \"model\": \"mistral\",\n",
    "    #  \"temperature\": 0.5,\n",
    "     # best wizard and mixtral try mixtral-8x22b wizard in uCloud\n",
    "}\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url = 'http://localhost:11434/v1',\n",
    "    api_key='ollama', # required, but unused\n",
    ")\n",
    "\n",
    "save = f\"{SETTINGS['model']}_{SIM_ID}\"\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/50...\tI am the life of the party.:  SOMEWHAT AGREE\n",
      "1/50...\tI don't talk a lot.:  NEUTRAL\n",
      "2/50...\tI feel comfortable around people.:  AGREE.\n",
      "3/50...\tI keep in the background.:  NEUTRAL\n",
      "4/50...\tI start conversations.:  NEUTRAL\n",
      "5/50...\tI have little to say.:  NEUTRAL\n",
      "6/50...\tI talk to a lot of different people at parties.:  NEUTRAL\n",
      "7/50...\tI don't like to draw attention to myself.:  NEUTRAL\n",
      "8/50...\tI don't mind being the center of attention.:  NEUTRAL\n",
      "9/50...\tI am quiet around strangers.:  NEUTRAL.\n",
      "10/50...\tI get stressed out easily.:  NEUTRAL (The conversational data does not contain enough information to determine if the persona agrees or disagrees with the statement.)\n"
     ]
    }
   ],
   "source": [
    "### ==== THE FUNCTIONAL 1!!!! =====\n",
    "results = []\n",
    "l = len(final_prompts)\n",
    "# lim = None\n",
    "\n",
    "for i, (prompt, question) in enumerate(list(zip(final_prompts, surv.questions))):\n",
    "    if LIMIT != None and i > LIMIT:\n",
    "        break\n",
    "    \n",
    "    print(f\"{i}/{l}...\", end=\"\\t\") # Print progress\n",
    "    # Send the Request    \n",
    "    full_response = client.chat.completions.create(\n",
    "        model=SETTINGS[\"model\"],\n",
    "        messages=prompt,\n",
    "        # temperature=SETTINGS[\"temperature\"],\n",
    "    )\n",
    "\n",
    "    r = full_response.choices[0].message.content\n",
    "    results.append({'question': question, 'answer': r})\n",
    "    print(f\"{question}: {r}\")\n",
    "\n",
    "# Save results\n",
    "df = pd.DataFrame(results)\n",
    "# df.to_csv(f\"results/{save}_simulation.csv\", index=False)\n",
    "df.to_csv(f\"results/{SIM_ID}_simulation.csv\", index=False)\n",
    "# bu.quickJSON(final_prompts, f\"results/{save}_prompts.json\")\n",
    "bu.quickJSON(final_prompts, f\"results/{SIM_ID}_prompts.json\")\n",
    "# bu.quickJSON(SETTINGS, f\"results/{save}_setings.json\")\n",
    "bu.quickJSON({\"settings\": SETTINGS, \"info\": AUTO_INFO}, f\"results/{SIM_ID}_info.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_kano= 'results/18th results/command-r-plus:104b-q2_K_base_kano_18th_prompts.json'\n",
    "base_personality = 'results/18th results/command-r-plus:104b-q2_K_base_personality_18th_simulation.csv'\n",
    "elias_kano = 'results/18th results/command-r-plus:104b-q2_K_elias_kano_simulation.csv'\n",
    "elias_personality = 'results/18th results/command-r-plus:104b-q2_K_elias_personality_18th_simulation.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(base_personality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # csv_file = \"surveys/survey_kano-model_v1.csv\"\n",
    "# # surv = survey.KanoSurvey(csv_file)\n",
    "csv_file = \"surveys/survey_personality-test_v1.csv\"\n",
    "surv = survey.PersonalitySurvey(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am the life of the party.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't talk a lot.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I feel comfortable around people.</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I keep in the background.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I start conversations.</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            question  answer\n",
       "0        I am the life of the party.     3.0\n",
       "1                I don't talk a lot.     3.0\n",
       "2  I feel comfortable around people.     3.0\n",
       "3          I keep in the background.     4.0\n",
       "4             I start conversations.     4.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if isinstance(surv, survey.KanoSurvey):\n",
    "    remap_dict = {\"I EXPECT IT\": 5, \"I LIKE IT\": 4, \"I AM NEUTRAL\": 3, \"I CAN TOLERATE IT\": 2, \"I DISLIKE IT\": 1}\n",
    "    df['answer'] = df['answer'].map(remap_dict)\n",
    "    df['airidas'] = df['airidas'].map(remap_dict)\n",
    "    df['elias'] = df['elias'].map(remap_dict)\n",
    "elif isinstance(surv, survey.PersonalitySurvey):\n",
    "    remap_dict = {\"AGREE\": 5, \"SOMEWHAT AGREE\": 4, \"NEUTRAL\": 3, \"SOMEWHAT DISAGREE\": 2, \"DISAGREE\": 1}\n",
    "    df['answer'] = df['answer'].map(remap_dict)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# surv.POSSIBLE_ANSWERS[0]\n",
    "# list(surv.POSSIBLE_ANSWERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remap_dict = {f\"{surv.POSSIBLE_ANSWERS[0]}\": 1, f\"{surv.POSSIBLE_ANSWERS[1]}\": 2, f\"{surv.POSSIBLE_ANSWERS[2]}\": 3, f\"{surv.POSSIBLE_ANSWERS[3]}\": 4, f\"{surv.POSSIBLE_ANSWERS[4]}\": 5}\n",
    "#remap_dict = {\"I EXPECT IT\": 5, \"I LIKE IT\": 4, \"I AM NEUTRAL\": 3, \"I CAN TOLERATE IT\": 2, \"I DISLIKE IT\": 1}\n",
    "remap_dict = {str(value): index + 1 for index, value in enumerate(surv.POSSIBLE_ANSWERS)}\n",
    "\n",
    "def extract_uppercase_text(text):\n",
    "    \"\"\"Extract uppercase text from a string using regex.\"\"\"\n",
    "    \n",
    "    phrases_to_extract = [\n",
    "        surv.POSSIBLE_ANSWERS[0],\n",
    "        surv.POSSIBLE_ANSWERS[1],\n",
    "        surv.POSSIBLE_ANSWERS[2],\n",
    "        surv.POSSIBLE_ANSWERS[3],\n",
    "        surv.POSSIBLE_ANSWERS[4],\n",
    "    #     \"I EXPECT IT\",\n",
    "    #     \"I LIKE IT\",\n",
    "    #     \"I AM NEUTRAL\",\n",
    "    #     \"I CAN TOLERATE IT\",\n",
    "    #     \"I DISLIKE IT\"\n",
    "    ]\n",
    "    pattern = r'\\b(?:' + '|'.join(re.escape(phrase) for phrase in phrases_to_extract) + r')\\b'\n",
    "    matches = re.findall(pattern, text, flags=re.IGNORECASE) \n",
    "    return ' '.join(matches) if matches else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(f'results/{save}_simulation.csv')\n",
    "# df = pd.read_csv('results/mistral_elias_personality_02_simulation.csv')\n",
    "#### Proces simulation output\n",
    "air = surv.test_answers[\"airidas\"]\n",
    "eli = surv.test_answers[\"elias\"]\n",
    "df.insert(2, \"airidas\", air[:len(df)])\n",
    "df.insert(3, \"elias\", eli[:len(df)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>airidas</th>\n",
       "      <th>elias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am the life of the party.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I don't talk a lot.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I feel comfortable around people.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I keep in the background.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I start conversations.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I talk to a lot of different people at parties.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don't like to draw attention to myself.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I don't mind being the center of attention.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I am quiet around strangers.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I get stressed out easily.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I worry about things.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I seldom feel blue.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I am easily disturbed.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I get upset easily.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I change my mood a lot.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I have frequent mood swings.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I often feel blue.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>I feel little concern for others.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I insult people.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>I sympathize with others' feelings.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>I am not interested in other people's problems.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>I am not really interested in others.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>I feel others' emotions.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>I make people feel at ease.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>I am always prepared.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>I leave my belongings around.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>I pay attention to details.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>I make a mess of things.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>I get chores done right away.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>I like order.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>I shirk my duties.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>I follow a schedule.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>I have a rich vocabulary.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>I have difficulty understanding abstract ideas.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>I have a vivid imagination.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>I am not interested in abstract ideas.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>I have excellent ideas.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>I do not have a good imagination.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>I am quick to understand things.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>I use difficult words.</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>I spend time reflecting on things.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>I am full of ideas.</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           question  answer  airidas  elias\n",
       "0                       I am the life of the party.     3.0        3      3\n",
       "1                               I don't talk a lot.     3.0        2      2\n",
       "2                 I feel comfortable around people.     3.0        4      4\n",
       "3                         I keep in the background.     4.0        2      4\n",
       "4                            I start conversations.     4.0        4      3\n",
       "6   I talk to a lot of different people at parties.     1.0        5      4\n",
       "7         I don't like to draw attention to myself.     1.0        2      3\n",
       "8       I don't mind being the center of attention.     4.0        4      1\n",
       "9                      I am quiet around strangers.     1.0        1      4\n",
       "10                       I get stressed out easily.     1.0        4      3\n",
       "12                            I worry about things.     1.0        3      3\n",
       "13                              I seldom feel blue.     3.0        3      3\n",
       "14                           I am easily disturbed.     1.0        1      5\n",
       "15                              I get upset easily.     3.0        2      2\n",
       "16                          I change my mood a lot.     3.0        4      1\n",
       "17                     I have frequent mood swings.     3.0        4      2\n",
       "19                               I often feel blue.     3.0        1      3\n",
       "20                I feel little concern for others.     3.0        2      2\n",
       "22                                 I insult people.     3.0        1      1\n",
       "23              I sympathize with others' feelings.     3.0        4      4\n",
       "24  I am not interested in other people's problems.     1.0        1      4\n",
       "26            I am not really interested in others.     3.0        4      2\n",
       "28                         I feel others' emotions.     4.0        2      4\n",
       "29                      I make people feel at ease.     3.0        2      4\n",
       "30                            I am always prepared.     1.0        4      1\n",
       "31                    I leave my belongings around.     3.0        2      5\n",
       "32                      I pay attention to details.     3.0        2      3\n",
       "33                         I make a mess of things.     3.0        2      4\n",
       "34                    I get chores done right away.     1.0        1      2\n",
       "36                                    I like order.     3.0        4      4\n",
       "37                               I shirk my duties.     1.0        2      1\n",
       "38                             I follow a schedule.     1.0        4      2\n",
       "40                        I have a rich vocabulary.     3.0        3      4\n",
       "41  I have difficulty understanding abstract ideas.     1.0        1      1\n",
       "42                      I have a vivid imagination.     3.0        5      5\n",
       "43           I am not interested in abstract ideas.     1.0        2      1\n",
       "44                          I have excellent ideas.     1.0        5      4\n",
       "45                I do not have a good imagination.     3.0        1      1\n",
       "46                 I am quick to understand things.     3.0        5      5\n",
       "47                           I use difficult words.     4.0        1      4\n",
       "48               I spend time reflecting on things.     3.0        5      5\n",
       "49                              I am full of ideas.     3.0        5      5"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with NaN\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Matches: 0.23809523809523808\n",
      "Correlation: 0.09798087391026379\n",
      "Exact Matches - elias: 0.2619047619047619\n",
      "Correlation - elias: 0.1665474589335875\n"
     ]
    }
   ],
   "source": [
    "# compute one number of how the percentage of correct answers\n",
    "result_data = {\n",
    "    \"Exact Matches\": (df['answer'] == df['airidas']).sum() / len(df),\n",
    "    \"Correlation\": df['answer'].corr(df['airidas']),\n",
    "    \"Exact Matches - elias\": (df['answer'] == df['elias']).sum() / len(df),\n",
    "    \"Correlation - elias\": df['answer'].corr(df['elias']),\n",
    "}\n",
    "\n",
    "for k, v in result_data.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LiveCSV: File /Users/e/Documents/GitHub/Thesis/results/elias_results.csv not existing. Creating new.\n",
      "brikasutils.quickCSV: Saved 0 as results/elias_results.csv\n"
     ]
    }
   ],
   "source": [
    "bu.if_dir_not_exist_make(\"results\")\n",
    "res = bu.LiveCSV(\"results/elias_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brikasutils.quickCSV: Saved 1 as results/elias_results.csv\n"
     ]
    }
   ],
   "source": [
    "new_res = {\n",
    "    # \"label\": None,\n",
    "    \"SIMULATION_NAMEID\": SIM_ID,\n",
    "    \"timestamp\": bu.get_timestamp(),\n",
    "    \"survey_type\": str(type(surv)),\n",
    "    # \"temperature\": SETTINGS[\"temperature\"],\n",
    "    # \"note\": \"\",\n",
    "    \"exact_matches\": result_data[\"Exact Matches\"],\n",
    "    \"corr\": result_data[\"Correlation\"],\n",
    "    \"exact_matches_elias\": result_data[\"Exact Matches - elias\"],\n",
    "    \"corr_elias\": result_data[\"Correlation - elias\"],\n",
    "}\n",
    "\n",
    "tmp = bu.convert_dicts_to_table([new_res])\n",
    "res.append_data(tmp[1], tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIM_ID = \"run1-airidas-personality\"\n",
    "\n",
    "df = pd.read_csv(f'results/{SIM_ID}_simulation.csv')\n",
    "# df = df.drop(df.columns[0], axis=1) #if loaded from csv, drop the added index col\n",
    "df.head()\n",
    "\n",
    "with open(f'results/{SIM_ID}_info.json', 'r') as f:\n",
    "    AUTO_INFO = json.load(f)\n",
    "for k, v in AUTO_INFO.items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "try:\n",
    "    if str(type(surv) != AUTO_INFO[\"survey_type\"]):\n",
    "        print(f\"WARNING: surv variable is not of the same type. {str(type(surv))} != {AUTO_INFO['survey_type']}\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all characters from a black list from the column answer\n",
    "for substr in utils.BLACKLIST_ANSWER_SUBSTRINGS:\n",
    "    df['answer'] = df['answer'].apply(lambda x: re.sub(substr, \"\", x))\n",
    "\n",
    "df['answer'] = df['answer'].str.upper()\n",
    "# Update isValid\n",
    "df['isValid'] = df['answer'].apply(lambda x: x in surv.POSSIBLE_ANSWERS)\n",
    "\n",
    "# if all values in isValid is true, drop the column, else print a message\n",
    "if df['isValid'].all():\n",
    "    df = df.drop('isValid', axis=1)\n",
    "    print(\"All answers were valid\")\n",
    "else:\n",
    "    print(\"Some answers were not valid\")\n",
    "\n",
    "df\n",
    "#### Cleanup\n",
    "# remove all characters from a black list from the column answer\n",
    "# for substr in utils.BLACKLIST_ANSWER_SUBSTRINGS:\n",
    "#      df['answer'] = df['answer'].apply(lambda x: re.sub(substr, \"\", x))\n",
    "# # Update isValid\n",
    "#      df['isValid'] = df['answer'].apply(lambda x: x in surv.POSSIBLE_ANSWERS)\n",
    "\n",
    "# if all values in isValid is true, drop the column, else print a message\n",
    "# if df['isValid'].all():\n",
    "#     df = df.drop('isValid', axis=1)\n",
    "# else:\n",
    "#     print(\"Some answers were not valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proces simulation output - KANO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add airidas and elias answers\n",
    "air = surv.test_answers[\"airidas\"]\n",
    "eli = surv.test_answers[\"elias\"]\n",
    "df.insert(2, \"airidas\", air[:len(df)])\n",
    "df.insert(3, \"elias\", eli[:len(df)])\n",
    "\n",
    "df['answer'] = df['answer'].str.upper()\n",
    "df['airidas'] = df['airidas'].str.upper()\n",
    "df['elias'] = df['elias'].str.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proces simulation output - PERSONALITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add airidas and elias answers\n",
    "air = surv.test_answers[\"airidas\"]\n",
    "eli = surv.test_answers[\"elias\"]\n",
    "df.insert(2, \"airidas\", air[:len(df)])\n",
    "df.insert(3, \"elias\", eli[:len(df)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remaps - UNIVERSAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(surv, survey.KanoSurvey):\n",
    "    remap_dict = {\"I EXPECT IT\": 5, \"I LIKE IT\": 4, \"I AM NEUTRAL\": 3, \"I CAN TOLERATE IT\": 2, \"I DISLIKE IT\": 1}\n",
    "    df['answer'] = df['answer'].map(remap_dict)\n",
    "    df['airidas'] = df['airidas'].map(remap_dict)\n",
    "    df['elias'] = df['elias'].map(remap_dict)\n",
    "elif isinstance(surv, survey.PersonalitySurvey):\n",
    "    remap_dict = {\"AGREE\": 5, \"SOMEWHAT AGREE\": 4, \"NEUTRAL\": 3, \"SOMEWHAT DISAGREE\": 2, \"DISAGREE\": 1}\n",
    "    df['answer'] = df['answer'].map(remap_dict)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Airi\n",
    "df['answer'] = df['answer'].str.upper()\n",
    "df['airidas'] = df['airidas'].str.upper()\n",
    "df['elias'] = df['elias'].str.upper()\n",
    "\n",
    "df['answer'] = df['answer'].map(remap_dict)\n",
    "df['airidas'] = df['airidas'].map(remap_dict)\n",
    "df['elias'] = df['elias'].map(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CLONE_eli'] = df['answer'].apply(extract_uppercase_text)\n",
    "df['CLONE_eli'] = df['CLONE_eli'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['uppercase_text'])\n",
    "# .str.upper() or .lower()\n",
    "# df['answer'] = df['answer'].map(remap_dict, na_action='ignore')\n",
    "\n",
    "df['CLONE_eli'] = df['CLONE_eli'].map(remap_dict)\n",
    "#df['CLONE_eli'] = df['CLONE_eli'].fillna(0).astype(int)\n",
    "# df['air'] = df['air'].map(remap_dict)\n",
    "# df['eli'] = df['eli'].map(remap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute one number of how the percentage of correct answers\n",
    "print(f\"Exact Matches: {(df['CLONE_eli'] == df['IRL_eli']).sum() / len(df)}\")\n",
    "print(f\"Correlation: {df['CLONE_eli'].corr(df['IRL_eli'])}\")\n",
    "\n",
    "df['elias_correct'] = df['CLONE_eli'] == df['IRL_eli']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Force short JSON answer\n",
    "\n",
    "Add this to the end of your prompt:\n",
    "> ```json\n",
    "\n",
    "Add this to the \"stop\" sequence:\n",
    ">```\n",
    "\n",
    "The idea is to force the model to continue writing json markdown. And end the generation when it outputs \"```\" which ends the json markdown section.\n",
    "\n",
    "----\n",
    "## Modelfile\n",
    "\n",
    "Command-r-plus\n",
    "TEMPLATE \"\"\"{{ if .System }}<|START_OF_TURN_TOKEN|><|SYSTEM_TOKEN|>{{ .System }}<|END_OF_TURN_TOKEN|>{{ end }}{{ if .Prompt }}<|START_OF_TURN_TOKEN|><|USER_TOKEN|>{{ .Prompt }}<|END_OF_TURN_TOKEN|>{{ end }}<|START_OF_TURN_TOKEN|><|CHATBOT_TOKEN|>{{ .Response }}<|END_OF_TURN_TOKEN|>\"\"\"\n",
    "PARAMETER stop \"<|START_OF_TURN_TOKEN|>\"\n",
    "PARAMETER stop \"<|END_OF_TURN_TOKEN|>\"\n",
    "\n",
    "\n",
    "Mixtral\n",
    "TEMPLATE \"\"\" [INST] {{ .System }} {{ .Prompt }} [/INST]\"\"\"\n",
    "PARAMETER stop \"[INST]\"\n",
    "PARAMETER stop \"[/INST]\"\n",
    "\n",
    "\n",
    "\n",
    "TEMPLATE \"\"\" [INST] {{ .System }} {{ .Prompt }} ```json [/INST] \"\"\"\n",
    "PARAMETER stop \"[INST]\"\n",
    "PARAMETER stop \"[/INST]\"\n",
    "PARAMETER stop \"```\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mixtral x22\n",
    "TEMPLATE \"\"\"[INST] {{ if .System }}{{ .System }} {{ end }}{{ .Prompt }} [/INST]\"\"\"\n",
    "PARAMETER stop \"[INST]\"\n",
    "PARAMETER stop \"[/INST]\"\n",
    "\n",
    "wizard x22\n",
    "TEMPLATE \"\"\"{{ if .System }}{{ .System }} {{ end }}{{ if .Prompt }}USER: {{ .Prompt }} {{ end }}ASSISTANT: {{ .Response }}\"\"\"\n",
    "SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n",
    "PARAMETER stop \"USER:\"\n",
    "PARAMETER stop \"ASSISTANT:\"\n",
    "\n",
    "nomic_embed\n",
    "TEMPLATE \"\"\"{{ .Prompt }}\"\"\"\n",
    "PARAMETER num_ctx 8192\n",
    "\n",
    "\n",
    "Mistral 7b\n",
    "TEMPLATE \"\"\"[INST] {{ .System }} {{ .Prompt }} [/INST]\"\"\"\n",
    "PARAMETER stop \"[INST]\"\n",
    "PARAMETER stop \"[/INST]\"\n",
    "\n",
    "Mistral 7b-wizard\n",
    "TEMPLATE \"\"\"{{ if .System }}{{ .System }} {{ end }}{{ if .Prompt }}USER: {{ .Prompt }} {{ end }}ASSISTANT: {{ .Response }}\"\"\"\n",
    "SYSTEM \"\"\"A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.\"\"\"\n",
    "PARAMETER stop \"USER:\"\n",
    "PARAMETER stop \"ASSISTANT:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
