{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import brikasutils as bu\n",
    "importlib.reload(bu)\n",
    "import shared_utils as utils\n",
    "from shared_utils import systemMsg, userMsg, assistantMsg\n",
    "importlib.reload(utils)\n",
    "import survey\n",
    "importlib.reload(survey)\n",
    "import persona\n",
    "importlib.reload(persona)\n",
    "\n",
    "import ollama\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "from typing import List\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import survey\n",
    "import pandas as pd\n",
    "import re\n",
    "import importlib\n",
    "import shared_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "importlib.reload(utils)\n",
    "import brikasutils as bu\n",
    "importlib.reload(bu)\n",
    "\n",
    "def see_if_column_valid(column_name, df, msg=\"Verification failed for\"):\n",
    "    dff = df[df[column_name].isna()]\n",
    "    dfff = dff.groupby(\"sim_signature\").apply(lambda x: x[x['run_number'] == 1], include_groups=False)\n",
    "    print(f\"{msg}: {len(dff)} ({len(dfff)} unique)\")\n",
    "    return dfff\n",
    "\n",
    "MOST_IMPORTANT_COLUMNS = ['sim_signature', 'run_number', \"model\", \"survey_type\", \"base_sim_signature\", \"SUBJECT\", 'CTX_limit', \"retrieval method\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index all simulation files\n",
    "SIMULATIONS_DIR = \"analysis/sims-final-2\"\n",
    "\n",
    "sim_runs = []\n",
    "for root, dirs, files in os.walk(SIMULATIONS_DIR):\n",
    "    for file in files:\n",
    "        if file.split(\".\")[1] != \"json\":\n",
    "            print(f\"Invalid file (all must be json) {sim_run['path']}\")\n",
    "\n",
    "        sim_run = {}\n",
    "        sim_run[\"SIMULATION_ID\"] = file.split(\".\")[0]\n",
    "        sim_run[\"path\"] = os.path.join(root, file)\n",
    "        with open(sim_run[\"path\"], 'r') as f:\n",
    "            sim = json.load(f)\n",
    "        sim_run.update(sim[\"info\"][\"info\"])\n",
    "        sim_run.update(sim[\"info\"][\"settings\"])\n",
    "        sim_runs.append(sim_run)\n",
    "\n",
    "df = pd.DataFrame(sim_runs)\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(f\"Loaded {len(df)} simulation files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infer/Get Needed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_survey_type(row):\n",
    "    if \"survey_type\" in row and not pd.isna(row[\"survey_type\"]):\n",
    "        if row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            return \"KanoSurvey\"\n",
    "        elif row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            return \"PersonalitySurvey\"\n",
    "        else:\n",
    "            print(\"Unknown survey type\" + row[\"survey_type\"])\n",
    "\n",
    "    if \"prompt_count\" in row and not pd.isna(row[\"prompt_count\"]):\n",
    "        if row[\"prompt_count\"] == 50:\n",
    "            return \"PersonalitySurvey\"\n",
    "        elif row[\"prompt_count\"] == 40:\n",
    "            return \"KanoSurvey\"\n",
    "        else:\n",
    "            print(\"Unknown prompt count\" + row[\"prompt_count\"])\n",
    "\n",
    "    return None\n",
    "\n",
    "df[\"survey_type\"] = df.apply(infer_survey_type, axis=1) \n",
    "df[\"survey_type\"].value_counts()\n",
    "\n",
    "# extract_run_number\n",
    "def extract_run_number(sim_id):\n",
    "    try:\n",
    "        parts = sim_id.rsplit('_', 1)  # Attempt to split by the last underscore\n",
    "        if len(parts) == 2:  # Check if the split was successful\n",
    "            return pd.Series([parts[0], int(parts[-1])])\n",
    "        else:\n",
    "            print(f\"Error while processing {sim_id}\")\n",
    "            return pd.Series([pd.NA, pd.NA])  # Return None for last_number if split fails\n",
    "         \n",
    "    except Exception as e:  # Generic exception handling\n",
    "        print(f\"Error while processing {sim_id}\")\n",
    "        return pd.Series([pd.NA, pd.NA])\n",
    "\n",
    "df[['sim_signature', 'run_number']] = df['SIMULATION_ID'].apply(extract_run_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infer_if_simulation_is_base\n",
    "def infer_if_simulation_is_base(row):\n",
    "    if row[\"sim_signature\"][:4] == \"base\":\n",
    "        return True\n",
    "    return False\n",
    "    \n",
    "df[\"is_base\"] = df.apply(infer_if_simulation_is_base, axis=1)\n",
    "\n",
    "# Below: Vanity Print\n",
    "dff = df[df[\"is_base\"] == True]\n",
    "dff = dff.sort_values(by=['sim_signature', 'run_number'])\n",
    "dff = dff.dropna(axis=1, how='all')\n",
    "dfff = dff.groupby(\"sim_signature\").apply(lambda x: x[x['run_number'] == 1], include_groups=False)\n",
    "print(f\"Found {len(dff)} ({len(dfff)} unique) base simulations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map simulations to their base\n",
    "def map_simulation_to_base(row):\n",
    "    if row[\"is_base\"] == True:\n",
    "        return \"(base)\"\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"gpt-3.5-turbo\":\n",
    "        return \"base_kano_v2_gpt35\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"gpt-3.5-turbo\":\n",
    "        return \"base_personality_v2_gpt35\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"llama3-70b\":\n",
    "        return \"base-kano-29_llama3-70b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"llama3-70b\":\n",
    "        return \"base-pers-29_llama3-70b_V7\"\n",
    "    \n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"llama3-8b\":\n",
    "        return \"base-kano-29_llama3-8b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"llama3-8b\":\n",
    "        return \"base-pers-29_llama3-8b_V7\"\n",
    "    \n",
    "    if row[\"survey_type\"] == \"KanoSurvey\" and row[\"model\"] == \"mixtral-8x22b\":\n",
    "        return \"base-kano-29_mixtral-8x22b_V7\"\n",
    "\n",
    "    if row[\"survey_type\"] == \"PersonalitySurvey\" and row[\"model\"] == \"mixtral-8x22b\":\n",
    "        return \"base-pers-29_mixtral-8x22b_V7\"\n",
    "    \n",
    "    return pd.NA\n",
    "    \n",
    "df[\"base_sim_signature\"] = df.apply(map_simulation_to_base, axis=1)\n",
    "dff = see_if_column_valid(\"base_sim_signature\", df, \"Missing mappings\")\n",
    "if len(dff) == 0:\n",
    "    print(\"All mappings are valid\")\n",
    "else:\n",
    "    print(\"Not all mappings are valid. See the missing mappings below\")\n",
    "    display(dff)\n",
    "\n",
    "def infer_subject(row):\n",
    "    if row[\"is_base\"]:\n",
    "        return \"(base)\"\n",
    "    if \"SUBJECT\" in row and pd.notna(row[\"SUBJECT\"]):\n",
    "        if row[\"SUBJECT\"] == \"airidas\" or row[\"SUBJECT\"] == \"Airidas\" or row[\"SUBJECT\"] == \"airi\":\n",
    "            return \"airidas\"\n",
    "        if row[\"SUBJECT\"] == \"elias\" or row[\"SUBJECT\"] == \"eli\":\n",
    "            return \"elias\"\n",
    "        print(f\"Unknown subject: {row['SUBJECT']}\")\n",
    "        return pd.NA\n",
    "    if \"subject\" in row and pd.notna(row[\"subject\"]):\n",
    "        if row[\"subject\"] == \"airidas\" or row[\"subject\"] == \"Airidas\" or row[\"subject\"] == \"airi\":\n",
    "            return \"airidas\"\n",
    "        if row[\"subject\"] == \"elias\" or row[\"subject\"] == \"eli\":\n",
    "            return \"elias\"\n",
    "        print(f\"Unknown subject: {row['subject']}\")\n",
    "        return pd.NA\n",
    "    if row[\"sim_signature\"][:4] == \"airi\":\n",
    "        return \"airidas\"\n",
    "    if row[\"sim_signature\"][:3] == \"eli\":\n",
    "        return \"elias\"\n",
    "    return pd.NA\n",
    "\n",
    "df[\"SUBJECT\"] = df.apply(infer_subject, axis=1)\n",
    "dff = see_if_column_valid(\"SUBJECT\", df, \"Missing subjects\")\n",
    "if len(dff) == 0:\n",
    "    print(\"All subjects are valid\")\n",
    "else:\n",
    "    display(dff)\n",
    "\n",
    "df = utils.bring_to_front_important_columns(df, MOST_IMPORTANT_COLUMNS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surv_from_info(row):\n",
    "    if row[\"survey_type\"] == \"KanoSurvey\":\n",
    "        return survey.KanoSurvey()\n",
    "    elif row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "        return survey.PersonalitySurvey()\n",
    "    else:\n",
    "        raise Exception(\"Unknown survey type: \" + row[\"survey_type\"])\n",
    "\n",
    "all_possible_asnwers = [\"I LIKE IT\", \"I EXPECT IT\", \"I AM NEUTRAL\", \"I CAN TOLERATE IT\", \"I DISLIKE IT\", \"SOMEWHAT DISAGREE\", \"DISAGREE\", \"NEUTRAL\", \"SOMEWHAT AGREE\", \"AGREE\"]\n",
    "def extract_possible_answer(value):\n",
    "    for phrase in all_possible_asnwers:\n",
    "        pattern = r'(?i)' + re.escape(phrase)\n",
    "        match = re.search(pattern, value)\n",
    "        if match:\n",
    "            # if value != phrase:\n",
    "            #     er.append([value, phrase])  \n",
    "            return match.group()\n",
    "    return value  # Return the original value if no possible answer is found\n",
    "\n",
    "############ Invalid Answers ##################\n",
    "def get_invalid_answers(value):\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "    elif value == \"NaN\":\n",
    "        return \"\"\n",
    "    elif value in all_possible_asnwers:\n",
    "        return \"\"\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "def clean_simulation_QA(df) -> pd.DataFrame:\n",
    "    df['answer'] = df['answer'].apply(lambda x: x.strip())\n",
    "    for substr in utils.BLACKLIST_ANSWER_SUBSTRINGS:\n",
    "        df['answer'] = df['answer'].apply(lambda x: re.sub(substr, \"\", x))\n",
    "    df['answer'] = df['answer'].str.upper()\n",
    "    df['answer'] = df['answer'].apply(extract_possible_answer)\n",
    "\n",
    "    REMAP_MISSING_E = {\"AGRE\": \"AGREE\", \"SOMEWHAT AGRE\": \"SOMEWHAT AGREE\", \"SOMEWHAT DISAGRE\": \"SOMEWHAT DISAGREE\", \"DISAGRE\": \"DISAGREE\", \"I DON'T LIKE IT\": \"I DISLIKE IT\"}\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:].map(lambda x: REMAP_MISSING_E.get(x, x))\n",
    "\n",
    "    PARTIAL_MATCH_REMAP = {\"SOMEWHAT AG\":\"SOMEWHAT AGREE\" }\n",
    "    df[\"answer\"] = df[\"answer\"].apply(\n",
    "        lambda answer: next((value for key, value in PARTIAL_MATCH_REMAP.items() if key in answer), answer)\n",
    "    )\n",
    "\n",
    "    # Update isValid\n",
    "    df['isValid'] = df['answer'].apply(lambda x: x in all_possible_asnwers)\n",
    "\n",
    "    # if all values in isValid is true, drop the column, else print a message\n",
    "    if not df['isValid'].all():\n",
    "        print(\"Warning, some answers were not valid. See df['isValid']\")      \n",
    "\n",
    "    return df\n",
    "\n",
    "# Proces simulation output\n",
    "def add_airidas_and_elias_answers(df, surv) -> pd.DataFrame:\n",
    "    # Add airidas and elias answers\n",
    "    air = surv.test_answers[\"airidas\"]\n",
    "    eli = surv.test_answers[\"elias\"]\n",
    "\n",
    "    # Sanity Check\n",
    "    if len(air) != len(df):\n",
    "        raise Exception(f\"Survey and DF length mismatch {len(air)} != {len(df)}. Suvey type: {str(type(surv))}\")\n",
    "\n",
    "    df.insert(2, \"airidas\", air[:len(df)])\n",
    "    df.insert(3, \"elias\", eli[:len(df)])\n",
    "\n",
    "    # Convert to uppercase\n",
    "    if isinstance(surv, survey.KanoSurvey):\n",
    "        df['answer'] = df['answer'].str.upper()\n",
    "        df['airidas'] = df['airidas'].str.upper()\n",
    "        df['elias'] = df['elias'].str.upper()\n",
    "        \n",
    "    return df\n",
    "\n",
    "def remap_answers_to_integers(df, surv, remap_answer = True):\n",
    "    if isinstance(surv, survey.KanoSurvey):\n",
    "        remap_dict = {\"I EXPECT IT\": 5, \"I LIKE IT\": 4, \"I AM NEUTRAL\": 3, \"I CAN TOLERATE IT\": 2, \"I DISLIKE IT\": 1}\n",
    "        if remap_answer:\n",
    "            df['answer'] = df['answer'].str.upper()\n",
    "            df['answer'] = df['answer'].map(remap_dict)\n",
    "        df['airidas'] = df['airidas'].str.upper()\n",
    "        df['elias'] = df['elias'].str.upper()\n",
    "        \n",
    "        df['airidas'] = df['airidas'].map(remap_dict)\n",
    "        df['elias'] = df['elias'].map(remap_dict)\n",
    "    elif isinstance(surv, survey.PersonalitySurvey):\n",
    "        remap_dict = {\"AGREE\": 5, \"SOMEWHAT AGREE\": 4, \"NEUTRAL\": 3, \"SOMEWHAT DISAGREE\": 2, \"DISAGREE\": 1}\n",
    "        if remap_answer:\n",
    "            df['answer'] = df['answer'].map(remap_dict)\n",
    "\n",
    "    return df\n",
    "\n",
    "def evaluate_single_simulation_run(df, sim_row) -> dict:\n",
    "    # compute the percentage of correct answers and average loss (MAE)\n",
    "    p_corr_airidas = df['answer'].corr(df['airidas'])\n",
    "    p_corr_elias = df['answer'].corr(df['elias'])\n",
    "    mae_airi = (df['answer'] - df['airidas']).abs().sum() / len(df)\n",
    "    mae_eli = (df['answer'] - df['elias']).abs().sum() / len(df)\n",
    "\n",
    "    if sim_row[\"is_base\"]: mae, p_corr = pd.NA, pd.NA\n",
    "    elif sim_row[\"SUBJECT\"] == \"airidas\": mae, p_corr = mae_airi, p_corr_airidas\n",
    "    elif sim_row[\"SUBJECT\"] == \"elias\": mae, p_corr = mae_eli, p_corr_elias\n",
    "    else: raise Exception(\"Unknown subject\")\n",
    "\n",
    "    result_data = {\n",
    "        \"MAE\": mae,\n",
    "        \"MAE_airi\": mae_airi,\n",
    "        \"MAE_eli\": mae_eli,\n",
    "        \"p-corr\": p_corr,\n",
    "        \"p-corr_Airidas\": p_corr_airidas,\n",
    "        \"p-corr_Elias\": p_corr_elias,\n",
    "        \"question_count\": len(df),\n",
    "    }\n",
    "    return result_data\n",
    "\n",
    "\n",
    "\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"MAE_airi\", \"MAE_eli\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col not in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.append(col)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi-Sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATE_INVALID_SIMULATIONS = True\n",
    "# If one of the questions in a simulation was answered with an invalid asnwer,\n",
    "#   should the whole sim still be used while dropping the questions with invalid answers?\n",
    "\n",
    "invalid_vals = []\n",
    "tmp = []\n",
    "\n",
    "for index, sim_row in df.iterrows():\n",
    "    sim = utils.load_sim(sim_row[\"path\"])\n",
    "    dfQA = utils.dataframe_from_QA(sim[\"QA\"])\n",
    "    with bu.MutePrint():\n",
    "        surv = get_surv_from_info(sim_row)\n",
    "        dfQA = clean_simulation_QA(dfQA)\n",
    "    dfQA = add_airidas_and_elias_answers(dfQA, surv)\n",
    "\n",
    "    ## Check for invalid values\n",
    "    if not dfQA['isValid'].all():\n",
    "        invalid_vals.extend(dfQA.loc[~dfQA['isValid'], 'answer'].tolist())\n",
    "        \n",
    "        if EVALUATE_INVALID_SIMULATIONS:\n",
    "            print(f\"{sim_row['SIMULATION_ID']} has invalid value(s). Sim will be included with dropped rows.\")\n",
    "            dfQA = dfQA[dfQA['isValid'] == True]\n",
    "        else:\n",
    "            print(f\"Skipping {sim_row['SIMULATION_ID']} due to invalid answers\")\n",
    "            continue\n",
    "\n",
    "    dfQA = remap_answers_to_integers(dfQA, surv)\n",
    "    for key, value in evaluate_single_simulation_run(dfQA, sim_row = sim_row).items():\n",
    "        df.at[index, key] = round(value, 3) if not pd.isna(value) else value\n",
    "\n",
    "# Rename values\n",
    "df['CTX_limit'] = df['CTX_limit'].astype(str)\n",
    "df.loc[df['CTX_limit'] == \"0\", 'CTX_limit'] = '1-chunk'\n",
    "\n",
    "df = utils.bring_to_front_important_columns(df, MOST_IMPORTANT_COLUMNS)\n",
    "\n",
    "if len(invalid_vals) > 0:\n",
    "    print(f\"{len(invalid_vals)} Invalid values:\")\n",
    "    display(pd.DataFrame(invalid_vals, columns=[\"Invalid Values\"]))\n",
    "    if EVALUATE_INVALID_SIMULATIONS:\n",
    "        print(\"EVALUATE_INVALID_SIMULATIONS == True. All invalid values were dropped\")\n",
    "else:\n",
    "    print(\"All values are valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def getGlobalColorByParam(param):\n",
    "    if param == 'SUBJECT':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'survey_type':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'model':\n",
    "        color = 'lightgreen'\n",
    "    else:\n",
    "        color = 'salmon'\n",
    "    return color\n",
    "\n",
    "def super_format_ax(ax, custom_x_label_size=13):\n",
    "    tick_locations = ax.get_xticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_xticklabels()]\n",
    "    ax.set_xticks(tick_locations) \n",
    "    ax.set_xticklabels(tick_labels, fontsize=custom_x_label_size, fontweight=\"semibold\", rotation=0)\n",
    "\n",
    "    tick_locations_y = ax.get_yticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels_y = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_yticklabels()]\n",
    "    ax.set_yticks(tick_locations_y) \n",
    "    ax.set_yticklabels(tick_labels_y, fontsize=12,rotation=0, color='#808080')\n",
    "    ax.set_facecolor('#f5f5f5')\n",
    "\n",
    "def add_value_texts(grouped_data, ax):\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.017  # offset each text to avoid clutter\n",
    "    COLOR = '#606060'\n",
    "    for tick in pos:\n",
    "        ax.text(tick, mins[tick] - vertical_offset - 0.022, f'{mins[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO\n",
    "        ax.text(tick, medians[tick] + vertical_offset - 0.003, f'{medians[tick]:.2f}', horizontalalignment='center', size='11.5', color=COLOR) #TODO\n",
    "        ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import textwrap\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "dfQAs_kano = []\n",
    "dfQAs_pers = []\n",
    "dfQAs_pers_base = []\n",
    "dfQAs_kano_base = []\n",
    "for index, sim_row in df.iterrows():\n",
    "    sim = utils.load_sim(sim_row[\"path\"])\n",
    "    dfQA = utils.dataframe_from_QA(sim[\"QA\"])\n",
    "    with bu.MutePrint():\n",
    "        surv = get_surv_from_info(sim_row)\n",
    "        dfQA = clean_simulation_QA(dfQA)\n",
    "    dfQA = add_airidas_and_elias_answers(dfQA, surv)\n",
    "    dfQA = remap_answers_to_integers(dfQA, surv)\n",
    "\n",
    "    if sim_row[\"is_base\"]:\n",
    "        if sim_row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            dfQAs_kano_base.append(dfQA)\n",
    "        elif sim_row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            dfQAs_pers_base.append(dfQA)\n",
    "    else:\n",
    "        if sim_row[\"survey_type\"] == \"KanoSurvey\":\n",
    "            dfQAs_kano.append(dfQA)\n",
    "        elif sim_row[\"survey_type\"] == \"PersonalitySurvey\":\n",
    "            dfQAs_pers.append(dfQA)\n",
    "\n",
    "\n",
    "surv_kano = survey.KanoSurvey()\n",
    "surv_pers = survey.PersonalitySurvey()\n",
    "surv_kano.df = remap_answers_to_integers(surv_kano.df, surv_kano, remap_answer=False)\n",
    "surv_pers.df = remap_answers_to_integers(surv_pers.df, surv_pers, remap_answer=False)\n",
    "\n",
    "#########################################################\n",
    "#########################################################\n",
    "\n",
    "# Assuming the dataframes and lists of dataframes are defined and imported already\n",
    "val_counts_raw = {\n",
    "    \"kano-airidas\": {\n",
    "        \"data\": surv_kano.df['airidas'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"pers-airidas\": {\n",
    "        \"data\": surv_pers.df['airidas'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"kano-elias\": {\n",
    "        \"data\": surv_kano.df['elias'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    \"pers-elias\": {\n",
    "        \"data\": surv_pers.df['elias'].value_counts().sort_index(),\n",
    "        \"text\": \"real answers\",\n",
    "        \"color\": \"lightblue\",\n",
    "        },\n",
    "    'kano-LLMs-base': {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_kano_base]).value_counts().sort_index(),\n",
    "        \"text\": \"LLM base answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \"pers-LLMs-base\": {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_pers_base]).value_counts().sort_index(),\n",
    "        \"text\": \"LLM base answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    'kano-LLMs': {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_kano]).value_counts().sort_index(),\n",
    "        \"text\": \"persona endcoded LLM answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \"pers-LLMs\": {\n",
    "        \"data\": pd.concat([df['answer'] for df in dfQAs_pers]).value_counts().sort_index(),\n",
    "        \"text\": \"persona endcoded LLM answers\",\n",
    "        \"color\": \"lightgreen\",\n",
    "        },\n",
    "    \n",
    "}\n",
    "\n",
    "plt.figure(figsize=(10, 12))\n",
    "for i, (key, value) in enumerate(val_counts_raw.items(), start=1):\n",
    "    info = value.copy()\n",
    "    ax = plt.subplot(4, 2, i)\n",
    "    title_text = f\"Distribution for {value['text']}: {key}\"\n",
    "    wrapped_title = textwrap.fill(title_text, width=30)  # You can adjust width as needed\n",
    "    plt.title(wrapped_title, fontsize=10)\n",
    "    plt.xlabel('Answer Values')\n",
    "    plt.ylabel('Percentage (%)')\n",
    "\n",
    "    value = value[\"data\"]\n",
    "    # Calculating statistics on the original unnormalized counts\n",
    "    val_array = np.repeat(value.index, value.values)\n",
    "    mean = np.mean(val_array)\n",
    "    median = np.median(val_array)\n",
    "    mode = value.idxmax()\n",
    "    std_dev = np.std(val_array)\n",
    "    skewness = np.sum((val_array - mean)**3) / (len(val_array) * std_dev**3)\n",
    "    mae = np.mean(np.abs(val_array - mean))\n",
    "    mae_mode = np.mean(np.abs(val_array - mode))\n",
    "\n",
    "    stats_text = (\n",
    "        f'Mean: {mean:.2f}\\n'\n",
    "        f\"Rounded Mean: {round(mean)}\\n\"\n",
    "        f'Median: {median}\\n'\n",
    "        f'Mode: {mode}\\n'\n",
    "        f'Std. Dev.: {std_dev:.2f}\\n'\n",
    "        f'Skewness: {skewness:.2f}\\n\\n'\n",
    "        f'Mean guess MAE: {mae:.3f}\\n'\n",
    "        f'(Always guess mean: \"{round(mean)}\")\\n\\n'\n",
    "        f'Mode guess MAE: {mae_mode:.3f}\\n'\n",
    "        f'(Always guess mode: {mode})\\n\\n'\n",
    "    )\n",
    "    \n",
    "    plt.annotate(stats_text, xy=(1.05, 0.5), xycoords='axes fraction',\n",
    "                    fontsize=10, ha='left', va='center')\n",
    "\n",
    "    # Normalizing data just before plotting\n",
    "    value_normalized = (value / value.sum()) * 100\n",
    "    value_normalized.plot(kind='bar', ax=ax, color=info[\"color\"], linewidth=1, edgecolor='black')\n",
    "    ax.set_ylim(0, 60)\n",
    "    super_format_ax(ax, custom_x_label_size=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_kano.df['elias'].value_counts().sort_index()\n",
    "value = val_counts_raw[\"pers-elias\"]\n",
    "value = value[\"data\"]\n",
    "val_array = np.repeat(value.index, value.values)\n",
    "mean = np.mean(val_array)\n",
    "median = np.median(val_array)\n",
    "mode = value.idxmax()\n",
    "std_dev = np.std(val_array)\n",
    "skewness = np.sum((val_array - mean)**3) / (len(val_array) * std_dev**3)\n",
    "mae = np.mean(np.abs(val_array - mean))\n",
    "mae_mode = np.mean(np.abs(val_array - mode))\n",
    "\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how columns should be groped\n",
    "aggregation_dict = {\n",
    "    'MAE_airi': ['mean', 'std'],\n",
    "    'MAE_eli': ['mean', 'std'],\n",
    "    'MAE': ['mean', 'std'],\n",
    "    'run_number': ['count'],\n",
    "    'question_count': ['min'],\n",
    "    'p-corr_Airidas': ['mean', 'std'],\n",
    "    'p-corr_Elias': ['mean', 'std'],\n",
    "    'p-corr': ['mean', 'std'],\n",
    "}\n",
    "\n",
    "\n",
    "# Preserve the first entry of other columns\n",
    "for col in df.columns:\n",
    "    if col not in ['sim_signature', *list(aggregation_dict.keys())]:\n",
    "        aggregation_dict[col] = 'first'\n",
    "        \n",
    "# dfg stands for DataFrame Grouped.\n",
    "dfg = df.groupby('sim_signature').agg(aggregation_dict)\n",
    "\n",
    "# Renaming MultiIndex columns\n",
    "dfg.columns = ['_'.join(col).strip() if col[1] != 'first' else col[0] for col in dfg.columns.values]\n",
    "dfg.rename(columns={'run_number_count': 'n-runs'}, inplace=True)\n",
    "for key in aggregation_dict.keys():\n",
    "    if 'mean' in aggregation_dict[key]:\n",
    "        dfg.rename(columns={f\"{key}_mean\": key}, inplace=True)\n",
    "dfg = dfg.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dfg = dfg[dfg['is_base'] == True]\n",
    "global_base_scores = {\n",
    "    \"master\": base_dfg[['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    \"mean_guess\": {\n",
    "        \"kano\": 0.9125,\n",
    "        \"pers\": 1.210\n",
    "    },\n",
    "    \"by_subject\": {\n",
    "        \"airidas\": base_dfg[['MAE_airi']].mean().mean(),\n",
    "        \"elias\": base_dfg[['MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_survey\":{\n",
    "        \"KanoSurvey\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"PersonalitySurvey\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_model\":{\n",
    "        \"llama3-70b\": base_dfg[base_dfg['model'] == \"llama3-70b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"llama3-8b\": base_dfg[base_dfg['model'] == \"llama3-8b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"mixtral-8x22b\": base_dfg[base_dfg['model'] == \"mixtral-8x22b\"][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_survey_subject\":{\n",
    "        \"PersAiri\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_airi']].mean().mean(),\n",
    "        \"PersEli\": base_dfg[base_dfg['survey_type'] == \"PersonalitySurvey\"][['MAE_eli']].mean().mean(),\n",
    "        \"KanoAiri\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_airi']].mean().mean(),\n",
    "        \"KanoEli\": base_dfg[base_dfg['survey_type'] == \"KanoSurvey\"][['MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"by_simulation\": {\n",
    "        \"kano_llama3-70b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_llama3-70b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"kano_llama3-8b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_llama3-8b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"kano_mixtral-8x22b\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "        \"pers_mixtral-8x22b\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')][['MAE_airi', 'MAE_eli']].mean().mean(),\n",
    "    },\n",
    "    \"atomic\": {\n",
    "        \"base-kano_llama3-70b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_llama3-70b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-70b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_llama3-70b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_llama3-70b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-70b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-kano_llama3-8b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_llama3-8b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_llama3-8b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_llama3-8b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_llama3-8b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_llama3-8b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-kano_mixtral-8x22b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-kano_mixtral-8x22b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-kano-29_mixtral-8x22b_V7')]['MAE_eli'].mean(),\n",
    "        \"base-pers_mixtral-8x22b_airi\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_airi'].mean(),\n",
    "        \"base-pers_mixtral-8x22b_eli\": base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_eli'].mean(),\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bu.quickJSON(global_base_scores, \"global_base_scores.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_to_paired_base(row: pd.Series, df: pd.DataFrame):\n",
    "    if row[\"is_base\"]:\n",
    "        return {\n",
    "            \"dMAE_airi\": pd.NA,\n",
    "            \"dMAE_eli\": pd.NA,\n",
    "            \"dMAE\": pd.NA,\n",
    "        }\n",
    "    \n",
    "    # Individual base\n",
    "    base = df[(df[\"sim_signature\"] == row[\"base_sim_signature\"])]\n",
    "    if len(base) == 0:\n",
    "        raise Exception(f\"Base not found for {row['base_sim_signature']}\")\n",
    "    if len(base) > 1:\n",
    "        raise Exception(f\"Multiple bases found for {row['base_sim_signature']}. (Make sure you are using grouped df)\")\n",
    "\n",
    "    base = base.iloc[0]\n",
    "    airi = row[\"MAE_airi\"] - base[\"MAE_airi\"]\n",
    "    eli = row[\"MAE_eli\"] - base[\"MAE_eli\"]\n",
    "    subj = airi if row[\"SUBJECT\"] == \"airidas\" else eli\n",
    "\n",
    "    return {\n",
    "        \"dMAE_airi\": airi,\n",
    "        \"dMAE_eli\": eli,\n",
    "        \"dMAE\": subj,\n",
    "        \"MAE_base\": base[\"MAE_airi\"] if row[\"SUBJECT\"] == \"airidas\" else base[\"MAE_eli\"]\n",
    "    }\n",
    "\n",
    "def compare_to_custom_base(row: pd.Series, df: pd.DataFrame, base_val: float, base_name: str):    \n",
    "    if row[\"is_base\"]:\n",
    "        return {\n",
    "            f\"dMAE_{base_name}_airi\": pd.NA,\n",
    "            f\"dMAE_{base_name}_eli\": pd.NA,\n",
    "            f\"dMAE_{base_name}\": pd.NA,\n",
    "        }\n",
    "\n",
    "    airi = row[\"MAE_airi\"] - base_val\n",
    "    eli =  row[\"MAE_eli\"] - base_val\n",
    "    subj = airi if row[\"SUBJECT\"] == \"airidas\" else eli\n",
    "\n",
    "    return {\n",
    "        f\"dMAE_{base_name}_airi\": airi,\n",
    "        f\"dMAE_{base_name}_eli\": eli,\n",
    "        f\"dMAE_{base_name}\": subj,\n",
    "    }\n",
    "\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"sim_signature\",\"dMAE\", \"dMAE_airi\", \"dMAE_eli\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value in compare_to_custom_base(sim_row, dfg, base_val=global_base_scores[\"master\"], base_name=\"master\").items():\n",
    "        dfg.at[index, key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to base\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value in compare_to_paired_base(sim_row, dfg).items():\n",
    "        dfg.at[index, key] = value\n",
    "\n",
    "ADD_TO_MOST_IMPORTANT_COLUMNS = [\"sim_signature\",\"MAE\", \"MAE_base\"]\n",
    "for col in ADD_TO_MOST_IMPORTANT_COLUMNS:\n",
    "    if col in MOST_IMPORTANT_COLUMNS:\n",
    "        MOST_IMPORTANT_COLUMNS.remove(col)\n",
    "MOST_IMPORTANT_COLUMNS = ADD_TO_MOST_IMPORTANT_COLUMNS + MOST_IMPORTANT_COLUMNS\n",
    "dfg = utils.bring_to_front_important_columns(dfg, MOST_IMPORTANT_COLUMNS)\n",
    "print(f\"Total unique simulations: {len(dfg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz Global Bases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import textwrap\n",
    "from matplotlib import gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "fig.suptitle('Global Bases Visualizations')\n",
    "gs = gridspec.GridSpec(4, 2)\n",
    "\n",
    "# Define axes using the GridSpec\n",
    "axs = {\n",
    "    (0, 0): fig.add_subplot(gs[0, 0]),\n",
    "    (0, 1): fig.add_subplot(gs[0, 1]),\n",
    "    (1, 0): fig.add_subplot(gs[1, 0]),\n",
    "    (1, 1): fig.add_subplot(gs[1, 1]),\n",
    "    (2, 0): fig.add_subplot(gs[2, 0]),\n",
    "    (2, 1): fig.add_subplot(gs[2, 1]),\n",
    "    (3, 0): fig.add_subplot(gs[3, 0]),\n",
    "    (3, 1): fig.add_subplot(gs[2:4, 1])  # Span 'Non-aggregated LLM' across two vertical spaces\n",
    "}\n",
    "\n",
    "# Data dictionary to align with subplot axes\n",
    "plot_data = {\n",
    "    (0, 0): ('by_survey', 'Aggregated LLM: By Survey', \"salmon\"),\n",
    "    (0, 1): ('by_subject', 'Aggregated LLM: By Subject', \"salmon\"),\n",
    "    (1, 0): ('by_survey_subject', 'Aggregated LLM: By Survey Subject', \"salmon\"),\n",
    "    (1, 1): ('by_model', 'Aggregated LLM: By Model', \"salmon\"),\n",
    "    (2, 0): ('by_simulation', 'Aggregated LLM: By Configuration', \"salmon\"),\n",
    "    (3, 0): ('mean_guess', 'Real Mean Guess bases', \"lightblue\"),\n",
    "    (3, 1): ('atomic', 'Non-aggregated (paired) LLM', \"lightgreen\")\n",
    "}\n",
    "\n",
    "# Loop through to plot each graph\n",
    "for pos, (key, title, color) in plot_data.items():\n",
    "    ax = axs[pos]\n",
    "    title_text = textwrap.fill(title, width=30)  \n",
    "    ax.set_title(title_text, fontsize=10)\n",
    "\n",
    "    if key == 'master':\n",
    "        ax.barh('Master', global_base_scores[key], color=color, edgecolor='black', linewidth=1)\n",
    "    else: \n",
    "        df = pd.DataFrame.from_dict(global_base_scores[key], orient='index', columns=['Value'])\n",
    "        bars = df.plot.barh(ax=ax, legend=False, color=color, edgecolor='black', linewidth=1)\n",
    "        \n",
    "        # Add value annotations to each bar\n",
    "        for bar in bars.patches:\n",
    "            bar_value = bar.get_width()\n",
    "            ax.text(bar.get_width() + df['Value'].max()*0.02, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{bar_value:.2f}', va='center', ha='left', color='#606060', fontsize=11)\n",
    "            \n",
    "    # Style adjustments\n",
    "    ax.set_facecolor('#f5f5f5')\n",
    "    ax.set_xlim(0, 2.0)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See info for giving to chatbot for code gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGNORE_COLS = [\"date\", \"EMBED_MODEL\", \"avg_tokens_in_prompt\", \"chunk_count\", \"OVERLAP_SIZE\", \"RETRIEVAL_PROMPT\", \"SIMULATION_ID\", \"path\", \"survey\", ]\n",
    "\n",
    "for col in dfg.columns:\n",
    "    if col in IGNORE_COLS:\n",
    "        continue  # Skip the columns from the IGNORE_COLS list\n",
    "    dtype = dfg[col].dtype\n",
    "    uniq_vals = dfg[col].unique()\n",
    "    uniq_count = len(uniq_vals)\n",
    "    na_count = dfg[col].isna().sum()\n",
    "    print(f\"{col}, dtype: {dtype}, unique count: {uniq_count}, NA values: {na_count}\", end=\"\")\n",
    "    \n",
    "    # Condition to check length of unique values and print them if < 5 and each < 25 chars\n",
    "    if uniq_count < 8 and all(len(str(val)) <= 150 for val in uniq_vals):\n",
    "        print(f\", Unique values: {uniq_vals}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viz v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "def getGlobalColorByParam(param):\n",
    "    if param == 'SUBJECT':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'survey_type':\n",
    "        color = 'lightblue'\n",
    "    elif param == 'model':\n",
    "        color = 'lightgreen'\n",
    "    else:\n",
    "        color = 'salmon'\n",
    "    return color\n",
    "\n",
    "def super_format_ax(ax, custom_x_label_size=13):\n",
    "    tick_locations = ax.get_xticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_xticklabels()]\n",
    "    ax.set_xticks(tick_locations) \n",
    "    ax.set_xticklabels(tick_labels, fontsize=custom_x_label_size, fontweight=\"semibold\", rotation=0)\n",
    "\n",
    "    tick_locations_y = ax.get_yticks()\n",
    "    # Retrieve and wrap the existing labels\n",
    "    tick_labels_y = [textwrap.fill(label.get_text(), width=8, break_long_words=True, break_on_hyphens=True) \n",
    "                for label in ax.get_yticklabels()]\n",
    "    ax.set_yticks(tick_locations_y) \n",
    "    ax.set_yticklabels(tick_labels_y, fontsize=12,rotation=0, color='#808080')\n",
    "    ax.set_facecolor('#f5f5f5')\n",
    "\n",
    "def add_value_texts(grouped_data, ax):\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.017  # offset each text to avoid clutter\n",
    "    COLOR = '#606060'\n",
    "    for tick in pos:\n",
    "        ax.text(tick, mins[tick] - vertical_offset - 0.022, f'{mins[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO\n",
    "        ax.text(tick, medians[tick] + vertical_offset - 0.003, f'{medians[tick]:.2f}', horizontalalignment='center', size='11.5', color=COLOR) #TODO\n",
    "        ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='10', color=COLOR) #TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your dataframe is named `dfg`\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model', 'SUBJECT', 'survey_type']\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters, 1):\n",
    "    ax = plt.subplot(1, 5, i)\n",
    "    ax.grid(True)\n",
    "    color = getGlobalColorByParam(param)\n",
    "    sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=1.2)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['MAE']\n",
    "    add_value_texts(grouped_data, ax)\n",
    "    #####################################################\n",
    "    \n",
    "    plt.title(f'MAE by {param}')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=0.6, top=1.35)\n",
    "    super_format_ax(ax)\n",
    "\n",
    "    # Adding horizontal lines for guidelines\n",
    "    line1, line2 = plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')\n",
    "    if i == 1:  # Only need these once for creating the legend\n",
    "        lines.extend([line1, line2])\n",
    "        labels.extend(['Real Mean Gues for kano: 0.9125', 'Real Mean Gues for pers: 1.210'])\n",
    "\n",
    "for ax in plt.gcf().axes:  # Go over all subplots in the figure\n",
    "    ax.set_xlabel('') \n",
    "plt.tight_layout()\n",
    "plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "plt.suptitle(f'\\n\\nMAE. (Lower is better), n={len(filtered_df)}', y=1.13, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "\n",
    "\n",
    "# Assuming your dataframe is named `df`\n",
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv)]\n",
    "    parameters = ['retrieval method', 'CTX_limit', 'model', 'SUBJECT']\n",
    "    \n",
    "    lines, labels = [], [] # To keep track of legend handles\n",
    "    for i, param in enumerate(parameters, 1):\n",
    "        ax = plt.subplot(1, 4, i)\n",
    "        ax.grid(True)\n",
    "        \n",
    "        color = getGlobalColorByParam(param)\n",
    "        sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=2)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)['MAE']\n",
    "        add_value_texts(grouped_data, ax)\n",
    "        #####################################################\n",
    "        \n",
    "        plt.title(f'MAE by {param}')\n",
    "        plt.ylabel('MAE')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=0.6, top=1.35)\n",
    "        super_format_ax(ax)\n",
    "\n",
    "        # Adding horizontal lines for guidelines\n",
    "        if srv == 'KanoSurvey':\n",
    "            lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--')]\n",
    "            labels_new = ['Real Mean Gues for kano: 0.9125']\n",
    "        elif srv == 'PersonalitySurvey':\n",
    "            lines_new = [plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "            labels_new = ['Real Mean Gues for pers: 1.210']\n",
    "        else:\n",
    "            lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "            labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "        \n",
    "        if i == 1:  # Only need these once for creating the legend\n",
    "            lines.extend(lines_new)\n",
    "            labels.extend(labels_new)\n",
    "\n",
    "    for ax in plt.gcf().axes:  # Go over all subplots in the figure\n",
    "        ax.set_xlabel('') \n",
    "    plt.tight_layout()\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "    plt.suptitle(f'MAE for {srv}.\\n (Lower is better), n={len(filtered_df)}', y=1.07, fontsize=16) \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming your dataframe is named `df`\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        plt.figure(figsize=(18, 10))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj)]\n",
    "        parameters = ['retrieval method', 'CTX_limit', 'model']\n",
    "        \n",
    "        lines, labels = [], [] # To keep track of legend handles\n",
    "        for i, param in enumerate(parameters, 1):\n",
    "            ax = plt.subplot(2, 3, i)\n",
    "            ax.grid(True)\n",
    "            \n",
    "            color = getGlobalColorByParam(param)\n",
    "            sns.boxplot(x=param, y='MAE', color=color, data=filtered_df, ax=ax, linewidth=3)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['MAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            \n",
    "            plt.title(f'MAE by {param}')\n",
    "            plt.ylabel('MAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=0.6, top=1.35) \n",
    "\n",
    "            # Adding horizontal lines for guidelines\n",
    "            if srv == 'KanoSurvey':\n",
    "                lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--')]\n",
    "                labels_new = ['Real Mean Gues for kano: 0.9125']\n",
    "            elif srv == 'PersonalitySurvey':\n",
    "                lines_new = [plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "                labels_new = ['Real Mean Gues for pers: 1.210']\n",
    "            else:\n",
    "                lines_new = [plt.axhline(y=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "                labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "            \n",
    "            if i == 1:  # Only need these once for creating the legend\n",
    "                lines.extend(lines_new)\n",
    "                labels.extend(labels_new)\n",
    "        plt.tight_layout()\n",
    "        plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=12)\n",
    "        plt.suptitle(f'MAE for {srv} & {subj}.\\n (Lower is better), n={len(filtered_df)}', y=1.05, fontsize=16)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dMAE - New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big boy - All 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model',  'SUBJECT', 'survey_type',]\n",
    "base_val = global_base_scores[\"master\"]\n",
    "base_name = \"master\"\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value in compare_to_custom_base(sim_row, dfg, base_val=base_val, base_name=base_name).items():\n",
    "        dfg.at[index, key] = value\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = plt.subplot(1, 5, i + 1)  # Horizontal layout of plots\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color='black', linewidth=2) \n",
    "    ax.axhspan(-1, 0, color='#dcedc1', alpha=0.5)  # Stylish green background below zero\n",
    "    ax.axhspan(0, 0.5, color='#ffaaa5', alpha=0.5)   # Stylish red background above zero    # Background color above zero\n",
    "    color = getGlobalColorByParam(param)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "    \n",
    "    # for tick in pos:\n",
    "    #     ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #     ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #     ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #####################################################\n",
    "    sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "    plt.title(f'By {param}')\n",
    "    plt.ylabel(f'MAE_from_paired_base')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=-0.95, top=0.32)  # Adjust y-limits\n",
    "\n",
    "\n",
    "    super_format_ax(ax)\n",
    "    add_value_texts(grouped_data, ax)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'dMAE\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.13, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'SUBJECT', 'survey_type',]\n",
    "for models in [['llama3-70b'], ['llama3-8b'], ['mixtral-8x22b']]:\n",
    "    plt.figure(figsize=(18, 6))\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models))]\n",
    "    for i, param in enumerate(parameters):\n",
    "        ax = plt.subplot(1, 4, i + 1)  # Horizontal layout of plots\n",
    "        ax.grid(True)\n",
    "        ax.axhline(0, color='black', linewidth=2) \n",
    "        ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "        ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "        color = getGlobalColorByParam(param)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "        mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "        pos = range(len(mins))  # Positions of the boxplots\n",
    "        vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "        for tick in pos:\n",
    "            ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        #####################################################\n",
    "        sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "        plt.title(f'By {param}')\n",
    "        plt.ylabel(f'dMAE')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=-0.3, top=0.32)  # Adjust y-limits\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'dMAE for {models}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three musketers (by subj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'survey_type']\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for models in [['mixtral-8x22b']]:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['SUBJECT'] == (subj))]\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {models} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three musketers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit', 'SUBJECT']\n",
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    for models in [['mixtral-8x22b']]:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['survey_type'] == (srv))]\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {models} for {srv}\\n (Lower is better), n={len(filtered_df)}\\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Gangsters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = ['retrieval method', 'CTX_limit']\n",
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        for models in [[\"llama3-8b\",'mixtral-8x22b']]:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            filtered_df = dfg[(dfg['is_base'] == False) & (dfg['model'].isin(models)) & (dfg['survey_type'] == (srv)) & (dfg['SUBJECT'] == (subj))]\n",
    "            base_sign = filtered_df.iloc[0][\"base_sim_signature\"]\n",
    "            base_name = utils.unclutterSignature(base_sign)\n",
    "            if subj == 'airidas': base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_airi'].mean()\n",
    "            else: base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_eli'].mean()\n",
    "\n",
    "            lines, labels = [], [] # To keep track of legend handles\n",
    "            for i, param in enumerate(parameters):\n",
    "                ax = plt.subplot(1, 2, i + 1)  # Horizontal layout of plots\n",
    "                ax.grid(True)\n",
    "                ax.axhline(0, color='black', linewidth=2) \n",
    "                ax.axhspan(-1, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "                ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "                color = getGlobalColorByParam(param)\n",
    "                #### Extract median values and their positions ######\n",
    "                grouped_data = filtered_df.groupby(param)['dMAE']\n",
    "                mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "                pos = range(len(mins))  # Positions of the boxplots\n",
    "                vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "                for tick in pos:\n",
    "                    ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                #####################################################\n",
    "                sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "                plt.title(f'By {param}')\n",
    "                plt.ylabel(f'dMAE')\n",
    "                plt.xticks(rotation=0) \n",
    "                plt.ylim(bottom=-0.32, top=0.32)  # Adjust y-limits\n",
    "                \n",
    "                # if len(models[0]) < 2:\n",
    "                #     if srv == 'KanoSurvey':\n",
    "                #         lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                #     elif srv == 'PersonalitySurvey':\n",
    "                #         lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "                #     else:\n",
    "                #         lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                #         labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                # if i == 1:  # Only need these once for creating the legend\n",
    "                #     lines.extend(lines_new)\n",
    "                #     labels.extend(labels_new)\n",
    "\n",
    "            # plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'\\n\\ndMAE for {models} for {srv} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n  Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)', y=1.15, fontsize=11) \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dMAE - Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Big boy - All 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 6))\n",
    "filtered_df = dfg[dfg['is_base'] == False]\n",
    "parameters = ['retrieval method', 'CTX_limit', 'model',  'SUBJECT', 'survey_type',]\n",
    "base_val = global_base_scores[\"master\"]\n",
    "base_name = \"master\"\n",
    "for index, sim_row in dfg.iterrows():\n",
    "    for key, value in compare_to_custom_base(sim_row, dfg, base_val=base_val, base_name=base_name).items():\n",
    "        dfg.at[index, key] = value\n",
    "\n",
    "lines, labels = [], [] # To keep track of legend handles\n",
    "for i, param in enumerate(parameters):\n",
    "    ax = plt.subplot(1, 5, i + 1)  # Horizontal layout of plots\n",
    "    ax.grid(True)\n",
    "    ax.axhline(0, color='black', linewidth=2) \n",
    "    ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "    ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "    color = getGlobalColorByParam(param)\n",
    "    #### Extract median values and their positions ######\n",
    "    grouped_data = filtered_df.groupby(param)['dMAE_master']\n",
    "    mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "    pos = range(len(mins))  # Positions of the boxplots\n",
    "    vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "    for tick in pos:\n",
    "        ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "    #####################################################\n",
    "    sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "    plt.title(f'By {param}')\n",
    "    plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "    plt.xticks(rotation=0) \n",
    "    plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "\n",
    "    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "    labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "    if i == 1:  # Only need these once for creating the legend\n",
    "        lines.extend(lines_new)\n",
    "        labels.extend(labels_new)\n",
    "\n",
    "plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.suptitle(f'dMAE\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "    base_val = global_base_scores[\"by_survey\"][srv]\n",
    "    base_name = srv[:4].lower()\n",
    "    for index, sim_row in dfg.iterrows():\n",
    "        for key, value in compare_to_custom_base(sim_row, dfg, base_val=base_val, base_name=base_name).items():\n",
    "            dfg.at[index, key] = value\n",
    "\n",
    "    filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv)]\n",
    "    parameters = ['retrieval method', 'CTX_limit',  'model','SUBJECT',]\n",
    "    plt.figure(figsize=(18, 6))  # Adjust the figure size for horizontal layouts\n",
    "    lines, labels = [], [] # To keep track of legend handles\n",
    "    for i, param in enumerate(parameters):\n",
    "        ax = plt.subplot(1, 4, i + 1)  # Horizontal layout of plots\n",
    "        ax.grid(True)\n",
    "        ax.axhline(0, color='black', linewidth=2) \n",
    "        ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "        ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "        color = getGlobalColorByParam(param)\n",
    "        #### Extract median values and their positions ######\n",
    "        grouped_data = filtered_df.groupby(param)[f'dMAE_{base_name}']\n",
    "        mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "        pos = range(len(mins))  # Positions of the boxplots\n",
    "        vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "        for tick in pos:\n",
    "            ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "        #####################################################\n",
    "        sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "        plt.title(f'By {param}')\n",
    "        plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "        plt.xticks(rotation=0) \n",
    "        plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "        \n",
    "        if srv == 'KanoSurvey':\n",
    "            lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "        elif srv == 'PersonalitySurvey':\n",
    "            lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "        else:\n",
    "            lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "            labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "        if i == 1:  # Only need these once for creating the legend\n",
    "            lines.extend(lines_new)\n",
    "            labels.extend(labels_new)\n",
    "    \n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f'dMAE for {srv}\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Three Musketers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subj in ['airidas', 'elias']:\n",
    "    for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "        base_name = srv[:4]\n",
    "        if subj == 'airidas': base_name += 'Airi'\n",
    "        else: base_name += 'Eli'\n",
    "        base_val = global_base_scores[\"by_survey_subject\"][base_name]\n",
    "        for index, sim_row in dfg.iterrows():\n",
    "            for key, value in compare_to_custom_base(sim_row, dfg, base_val=base_val, base_name=base_name).items():\n",
    "                dfg.at[index, key] = value\n",
    "\n",
    "        filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj)]\n",
    "        parameters = ['retrieval method', 'CTX_limit', 'model']\n",
    "        plt.figure(figsize=(18, 6))  # Adjust the figure size for horizontal layouts\n",
    "        lines, labels = [], [] # To keep track of legend handles\n",
    "        for i, param in enumerate(parameters):\n",
    "            ax = plt.subplot(1, 3, i + 1)  # Horizontal layout of plots\n",
    "            ax.grid(True)\n",
    "            ax.axhline(0, color='black', linewidth=2) \n",
    "            ax.axhspan(-0.55, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "            ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "            color = getGlobalColorByParam(param)\n",
    "            #### Extract median values and their positions ######\n",
    "            grouped_data = filtered_df.groupby(param)[f'dMAE_{base_name}']\n",
    "            mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "            pos = range(len(mins))  # Positions of the boxplots\n",
    "            vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "            for tick in pos:\n",
    "                ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "            #####################################################\n",
    "            sns.boxplot(x=param, y=f'dMAE_{base_name}', color=color, data=filtered_df)\n",
    "            plt.title(f'By {param}')\n",
    "            plt.ylabel(f'dMAE_{base_name}  {round(base_val,3)}')\n",
    "            plt.xticks(rotation=0) \n",
    "            plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "            \n",
    "            if srv == 'KanoSurvey':\n",
    "                lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "            elif srv == 'PersonalitySurvey':\n",
    "                lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "            else:\n",
    "                lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "            if i == 1:  # Only need these once for creating the legend\n",
    "                lines.extend(lines_new)\n",
    "                labels.extend(labels_new)\n",
    "        \n",
    "        plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle(f'dMAE for {srv} for {subj}\\n (Lower is better), n={len(filtered_df)}\\n Aggregated LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.10, fontsize=16) \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two Gansters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for llm in ['llama3-8b', 'llama3-70b', 'mixtral-8x22b']:\n",
    "    for subj in ['airidas', 'elias']:\n",
    "        for srv in ['KanoSurvey', \"PersonalitySurvey\"]:\n",
    "            filtered_df = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == srv) & (dfg['SUBJECT'] == subj) & (dfg['model'] == llm)]\n",
    "            base_sign = filtered_df.iloc[0][\"base_sim_signature\"]\n",
    "            base_name = utils.unclutterSignature(base_sign)\n",
    "            if subj == 'airidas': base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_airi'].mean()\n",
    "            else: base_val = dfg[(dfg['sim_signature'] == base_sign)]['MAE_eli'].mean()\n",
    "            parameters = ['retrieval method', 'CTX_limit']\n",
    "            plt.figure(figsize=(10, 6))  # Adjust the figure size for horizontal layouts\n",
    "            lines, labels = [], [] # To keep track of legend handles\n",
    "            for i, param in enumerate(parameters):\n",
    "                ax = plt.subplot(1, 2, i + 1)  # Horizontal layout of plots\n",
    "                ax.grid(True)\n",
    "                ax.axhline(0, color='black', linewidth=2) \n",
    "                ax.axhspan(-0.95, 0, color='green', alpha=0.16)  # Stylish green background below zero\n",
    "                ax.axhspan(0, 0.32, color='red', alpha=0.16)   # Stylish red background above zero    # Background color above zero\n",
    "                color = getGlobalColorByParam(param)\n",
    "                #### Extract median values and their positions ######\n",
    "                grouped_data = filtered_df.groupby(param)[f'dMAE']\n",
    "                mins, medians, maxs = grouped_data.min().values, grouped_data.median().values, grouped_data.max().values\n",
    "                pos = range(len(mins))  # Positions of the boxplots\n",
    "                vertical_offset = 0.01  # offset each text to avoid clutter\n",
    "                for tick in pos:\n",
    "                    ax.text(tick, mins[tick] - vertical_offset - 0.015, f'{mins[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, medians[tick] + vertical_offset, f'{medians[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                    ax.text(tick, maxs[tick] + vertical_offset , f'{maxs[tick]:.2f}', horizontalalignment='center', size='x-small', color='black', weight='semibold')\n",
    "                #####################################################\n",
    "                sns.boxplot(x=param, y=f'dMAE', color=color, data=filtered_df)\n",
    "                plt.title(f'By {param}')\n",
    "                plt.ylabel(f'dMAE_atomic  {round(base_val,3)}')\n",
    "                plt.xticks(rotation=0) \n",
    "                if base_val > 1.6: plt.ylim(bottom=-0.95, top=0.1) \n",
    "                else: plt.ylim(bottom=-0.55, top=0.32)  # Adjust y-limits\n",
    "                \n",
    "                if srv == 'KanoSurvey':\n",
    "                    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--', linewidth=2.5), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "                elif srv == 'PersonalitySurvey':\n",
    "                    lines_new = [plt.axhline(y=1.210 - base_val, color='red', linestyle='--', linewidth=2.5), plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}',f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}']\n",
    "                else:\n",
    "                    lines_new = [plt.axhline(y=0.9125 - base_val, color='blue', linestyle='--'), plt.axhline(y=1.210 - base_val, color='red', linestyle='--')]\n",
    "                    labels_new = [f'Real Mean Guess base for Kano: {round(0.9125 - base_val,3)}', f'Real Mean Guess base for pers: {round(1.210 - base_val,3)}']\n",
    "\n",
    "                if i == 1:  # Only need these once for creating the legend\n",
    "                    lines.extend(lines_new)\n",
    "                    labels.extend(labels_new)\n",
    "            \n",
    "            plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "            plt.tight_layout()\n",
    "            plt.suptitle(f'\\n\\ndMAE for {srv} for {subj} for {llm}\\n (Lower is better), n={len(filtered_df)}\\n Atomic LLM base: {base_name} = {round(base_val,3)} (y=0 is at MAE {round(base_val,3)})', y=1.16, fontsize=13) \n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == \"KanoSurvey\") & (dfg['SUBJECT'] == \"airidas\") & (dfg['model'] == \"llama3-8b\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dfg[(base_dfg['sim_signature'] == 'base-pers-29_mixtral-8x22b_V7')]['MAE_eli'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph nr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "        \"gap\": -0.280,\n",
    "        \"start-offset\": -0.12\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "        \"gap\": -0.055,\n",
    "        \"start-offset\": -0.03\n",
    "\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    ddf = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == graph[\"srv\"])].sort_values(ascending=True, by='dMAE').reset_index()\n",
    "    grouped_data = ddf.groupby(param)['dMAE']\n",
    "\n",
    "    # Create a plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    fig.suptitle(f\"Survey Type: {graph['srv']}\", fontsize=16, x=0.18, y=0.92)\n",
    "\n",
    "    # Create a horizontal bar plot with seaborn\n",
    "    sns.barplot(x='dMAE', y=ddf.index, data=ddf, orient='h', ax=ax)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('dMAE')\n",
    "    ax.set_ylabel('Configuration')\n",
    "\n",
    "    # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # Setting text properties\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    # Adding the table details for each bar at corresponding y position\n",
    "    # Assuming the maximum dMAE value is less than 5 for alignment purposes\n",
    "    # gap = -0.055\n",
    "    # start = -0.14\n",
    "    # x_positions = []\n",
    "    # for i in range(5):\n",
    "    #     x_positions.append(start + gap * i)\n",
    "    # print(x_positions)\n",
    "\n",
    "    gap = graph[\"gap\"]\n",
    "    start = min(ddf['dMAE']) + graph[\"start-offset\"]\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "    print(x_positions)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[0], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'CTX_limit'], **table_text_props)\n",
    "        ax.text(x=x_positions[2], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "        ax.text(x=x_positions[3], y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props)\n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s=\"SUBJECT\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s=\"CTX_limit\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[2], y=len(ddf), s=\"model\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[3], y=len(ddf), s=\"retrieval\", fontweight='bold', **table_text_props)\n",
    "\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.55)\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def various_or_single(x):\n",
    "    if x.nunique() == 1:\n",
    "        return x.iloc[0]\n",
    "    else:\n",
    "        return '(various)'\n",
    "\n",
    "# Determine aggregation methods based on column data types\n",
    "aggregations = {}\n",
    "for column, dtype in dfg.dtypes.items():\n",
    "    if dtype in ['int64', 'float64']:  # Add other numeric types if needed\n",
    "        aggregations[column] = 'mean'\n",
    "    else:\n",
    "        aggregations[column] = various_or_single\n",
    "\n",
    "# Apply group by with the dynamic aggregation dictionary\n",
    "group_cols = ['SUBJECT', 'model', \"survey_type\"]\n",
    "df_grouped = dfg.groupby(group_cols).agg(aggregations).drop(columns=group_cols).reset_index()\n",
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Calculate start and end points\n",
    "    ddf = df_grouped[(df_grouped['is_base'] == False) & (df_grouped['survey_type'] == graph[\"srv\"])].sort_values(ascending=False, by='MAE').reset_index()\n",
    "    ddf = ddf.drop(columns=[\"index\"])\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(23, 3))\n",
    "    fig.patch.set_facecolor('#efdbbd')\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "        print(row['end'] - row['start'])\n",
    "    \n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon'\n",
    "        group_signature = \" \".join([str(row[col]) for col in group_cols])\n",
    "        ax.barh(group_signature, row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "        \n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0.60, 1.82)\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    gap = -0.18\n",
    "    start = 0.58\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "    print(x_positions)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[0], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "        \n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s=\"SUBJECT\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s=\"model\", fontweight='bold', **table_text_props)\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.55)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "        # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for kano: 0.9125']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for pers: 1.210']\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('MAE')\n",
    "    ax.set_title('Change in MAE from Base')\n",
    "    super_format_ax(ax)\n",
    "    ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    fig.suptitle(f\"Survey type: {graph['srv']}\", fontsize=14, x=0.26, y=1.05)\n",
    "\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = [\n",
    "    {\n",
    "        \"srv\": \"PersonalitySurvey\",\n",
    "    },\n",
    "    {\n",
    "        \"srv\": \"KanoSurvey\",\n",
    "    },\n",
    "]\n",
    "\n",
    "for graph in graphs:\n",
    "    # Calculate start and end points\n",
    "    ddf = dfg[(dfg['is_base'] == False) & (dfg['survey_type'] == graph[\"srv\"])].sort_values(ascending=False, by='MAE').reset_index()\n",
    "\n",
    "    ddf['start'] = ddf['MAE_base']\n",
    "    ddf['end'] = ddf['MAE_base'] + ddf['dMAE']\n",
    "\n",
    "    # Create figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(23, 8))\n",
    "    fig.patch.set_facecolor('#efdbbd')\n",
    "\n",
    "    # Plot each bar\n",
    "    for i, row in ddf.iterrows():\n",
    "        color = 'lightgreen' if row['dMAE'] <= 0 else 'salmon' \n",
    "        ax.barh(row['sim_signature'], row['end'] - row['start'], left=row['start'], color=color)\n",
    "        ax.plot([row['MAE_base'], row['MAE_base']], [i-0.4, i+0.4], color='black', linewidth=2)\n",
    "\n",
    "    ax.set_yticks([]) # Remove Y-axis tick labels since we will replace them with detailed text\n",
    "    ax.set_xlim(0.60, 1.82)\n",
    "    table_text_props = {'verticalalignment': 'center', 'horizontalalignment': 'right'}\n",
    "\n",
    "    gap = -0.18\n",
    "    start = 0.58\n",
    "    x_positions = []\n",
    "    for i in range(4):\n",
    "        x_positions.append(start + gap * i)\n",
    "    print(x_positions)\n",
    "\n",
    "    for i in range(len(ddf)):\n",
    "        ax.text(x=x_positions[0], y=i, s=ddf.loc[i, 'SUBJECT'], **table_text_props)\n",
    "        ax.text(x=x_positions[1], y=i, s=ddf.loc[i, 'CTX_limit'], **table_text_props)\n",
    "        ax.text(x=x_positions[2], y=i, s=ddf.loc[i, 'model'], **table_text_props)\n",
    "        ax.text(x=x_positions[3], y=i, s=ddf.loc[i, 'retrieval method'], **table_text_props)\n",
    "        # Draw horizontal lines between rows\n",
    "        ax.axhline(y=i - 0.5, xmin=0, xmax=1, color='lightgray', linewidth=0.8)\n",
    "\n",
    "    # Add table column headers\n",
    "    ax.text(x=x_positions[0], y=len(ddf), s=\"SUBJECT\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[1], y=len(ddf), s=\"CTX_limit\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[2], y=len(ddf), s=\"model\", fontweight='bold', **table_text_props)\n",
    "    ax.text(x=x_positions[3], y=len(ddf), s=\"retrieval\", fontweight='bold', **table_text_props)\n",
    "    # Adjust the plot layout to make room for the table but with smaller gaps\n",
    "    plt.subplots_adjust(right=0.55)\n",
    "\n",
    "    lines = []\n",
    "    labels = []\n",
    "        # Adding horizontal lines for guidelines\n",
    "    if graph[\"srv\"] == 'KanoSurvey':\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for kano: 0.9125']\n",
    "    elif graph[\"srv\"] == 'PersonalitySurvey':\n",
    "        lines_new = [plt.axvline(x=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for pers: 1.210']\n",
    "    else:\n",
    "        lines_new = [plt.axvline(x=0.9125, color='blue', linestyle='--'), plt.axhline(y=1.210, color='red', linestyle='--')]\n",
    "        labels_new = ['Real Mean Guess for Kano: 0.9125', 'Real Mean Guess for pers: 1.210']\n",
    "    \n",
    "    lines.extend(lines_new)\n",
    "    labels.extend(labels_new)\n",
    "    plt.figlegend(lines, labels, loc='upper left', ncol=2, fontsize=10)\n",
    "\n",
    "    # Adding labels and title\n",
    "    ax.set_xlabel('MAE')\n",
    "    ax.set_title('Change in MAE from Base')\n",
    "    super_format_ax(ax)\n",
    "    ax.set_facecolor('#f8eee0')\n",
    "\n",
    "    fig.suptitle(f\"Survey type: {graph['srv']}\", fontsize=16, x=0.22, y=0.95)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min(ddf['dMAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle(f'dMAE for {srv}\\n (Lower is better) \\n Using paired LLM bases (y=0 for each row is set to the MAE of equivalent base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Old viz 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Set style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Sorting and filtering the dataframe for each plot\n",
    "sorted_airidas_personality = dfg[(dfg['survey_type'] == 'PersonalitySurvey')].sort_values('MAE_airi_mean', ascending=True)\n",
    "sorted_airidas_kano = dfg[(dfg['survey_type'] == 'KanoSurvey')].sort_values('MAE_airi_mean', ascending=True)\n",
    "sorted_elias_personality = dfg[(dfg['survey_type'] == 'PersonalitySurvey')].sort_values('MAE_eli_mean', ascending=True)\n",
    "sorted_elias_kano = dfg[(dfg['survey_type'] == 'KanoSurvey')].sort_values('MAE_eli_mean', ascending=True)\n",
    "\n",
    "# Custom color functions\n",
    "def get_colors_airidas(df):\n",
    "    colors = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['SUBJECT'] != 'airidas' and not row['is_base']:\n",
    "            colors.append('#bfd7ec')\n",
    "        elif row['is_base']:\n",
    "            colors.append('black')\n",
    "        else:\n",
    "            colors.append('#0c4da2')\n",
    "    return colors\n",
    "\n",
    "def get_colors_elias(df):\n",
    "    colors = []\n",
    "    for _, row in df.iterrows():\n",
    "        if row['SUBJECT'] != 'elias' and not row['is_base']:\n",
    "            colors.append('#adcbe3')\n",
    "        elif row['is_base']:\n",
    "            colors.append('black')\n",
    "        else:\n",
    "            colors.append('#0c4da2')\n",
    "    return colors\n",
    "\n",
    "colors_airidas_p = get_colors_airidas(sorted_airidas_personality)\n",
    "colors_airidas_k = get_colors_airidas(sorted_airidas_kano)\n",
    "colors_elias_p = get_colors_elias(sorted_elias_personality)\n",
    "colors_elias_k = get_colors_elias(sorted_elias_kano)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 14))\n",
    "fig.suptitle('Mean MAE Metrics by Sim Signature and Survey Type', fontsize=16)\n",
    "\n",
    "# Adding horizontal bars and error bars\n",
    "for (data, ax, colors, ylabel, title) in [\n",
    "    (sorted_airidas_personality, axs[0, 0], colors_airidas_p, 'sim_signature', 'Mean MAE_Airidas (PersonalitySurvey)'),\n",
    "    (sorted_airidas_kano, axs[1, 0], colors_airidas_k, 'sim_signature', 'Mean MAE_Airidas (KanoSurvey)'),\n",
    "    (sorted_elias_personality, axs[0, 1], colors_elias_p, 'sim_signature', 'Mean MAE_Elias (PersonalitySurvey)'),\n",
    "    (sorted_elias_kano, axs[1, 1], colors_elias_k, 'sim_signature', 'Mean MAE_Elias (KanoSurvey)')\n",
    "]:\n",
    "    sns.barplot(data=data, y=ylabel, x='MAE_airi_mean' if 'Airidas' in title else 'MAE_eli_mean', ax=ax, palette=colors, orient='h')\n",
    "    if 'Airidas' in title:\n",
    "        ax.errorbar(data['MAE_airi_mean'], data[ylabel], xerr=data['MAE_airi_std'], fmt='none', ecolor='red', capsize=3, elinewidth=1, alpha=1 )\n",
    "    else:\n",
    "        ax.errorbar(data['MAE_eli_mean'], data[ylabel], xerr=data['MAE_eli_std'], fmt='none', ecolor='red', capsize=3, elinewidth=1, alpha=1)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(title.split(' ')[1])\n",
    "    ax.set_ylabel(ylabel)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()\n",
    "\n",
    "###########################\n",
    "# Average the crossed results\n",
    "###########################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning analysis (NEW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'dfg' is your DataFrame\n",
    "# Filter out rows where 'is_base' is True\n",
    "df_filtered = dfg[dfg['is_base'] == False]\n",
    "\n",
    "# Create a figure for the plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))  # 2 rows, 2 columns\n",
    "fig.suptitle('Comparison of Models for Static vs Dynamic (Lower is better)', fontsize=16)\n",
    "\n",
    "# Each subplot for different combinations\n",
    "for i, (subject, survey_type) in enumerate([\n",
    "        ('elias', 'KanoSurvey'), ('elias', 'PersonalitySurvey'),\n",
    "        ('airidas', 'KanoSurvey'), ('airidas', 'PersonalitySurvey')]):\n",
    "\n",
    "    ax = axs[i//2, i%2]\n",
    "    \n",
    "    # Filter data for the specific group\n",
    "    df_group = df_filtered[(df_filtered['SUBJECT'] == subject) & (df_filtered['survey_type'] == survey_type)]\n",
    "    \n",
    "    # Separate further by model\n",
    "    df_group_8b = df_group[df_group['model'] == 'llama3-8b']\n",
    "    df_group_70b = df_group[df_group['model'] == 'llama3-70b']\n",
    "    df_group_8x22b = df_group[df_group['model'] == 'mixtral-8x22b']\n",
    "    \n",
    "    # Combine the data for a comparison by retrieval method and model\n",
    "    df_group_8b = df_group_8b.assign(Model='lamma3-8b')\n",
    "    df_group_70b = df_group_70b.assign(Model='lamma3-70b')\n",
    "    df_group_8x22b = df_group_8x22b.assign(Model='mixtral-8x22')\n",
    "    df_plot = pd.concat([df_group_8b, df_group_70b, df_group_8x22b])\n",
    "\n",
    "    # Select the correct metric based on the subject\n",
    "    if subject == 'elias':\n",
    "        metric_column = f'MAE_eli_mean'\n",
    "    if subject == 'airidas':\n",
    "        metric_column = f'MAE_airi_mean'\n",
    "    df_plot['Metric Value'] = df_plot[metric_column]\n",
    "    \n",
    "    # Create a bar chart\n",
    "    sns.barplot(data=df_plot, x='retrieval method', y='Metric Value', hue='Model', ax=ax, palette='viridis')\n",
    "    \n",
    "    # Setting the title and labels\n",
    "    ax.set_title(f'{subject.capitalize()} - {survey_type}')\n",
    "    ax.set_xlabel('Retrieval Method')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "\n",
    "# Adjust layout for better readability\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "\n",
    "##########################\n",
    "# Add base\n",
    "#########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'dfg' is your DataFrame\n",
    "# Filter out rows where 'is_base' is True and 'lamma3-70b'\n",
    "\n",
    "df_filtered = dfg[(dfg['is_base'] == False) & (dfg['model'] == 'llama3-8b')]\n",
    "\n",
    "# Create a figure for the plots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 12))  # 2 rows, 2 columns\n",
    "fig.suptitle('Comparison of CTX Limit Values for llama3-8b', fontsize=16)\n",
    "\n",
    "# Each subplot for different combinations\n",
    "for i, (subject, survey_type) in enumerate([\n",
    "        ('elias', 'KanoSurvey'), ('elias', 'PersonalitySurvey'),\n",
    "        ('airidas', 'KanoSurvey'), ('airidas', 'PersonalitySurvey')]):\n",
    "\n",
    "    ax = axs[i//2, i%2]\n",
    "    \n",
    "    # Filter data for the specific group\n",
    "    df_group = df_filtered[(df_filtered['SUBJECT'] == subject) & (df_filtered['survey_type'] == survey_type)]\n",
    "    \n",
    "    # Select the correct metric based on the subject\n",
    "    metric_column = f'p-corr_{subject.capitalize()}_mean'\n",
    "    df_group['Metric Value'] = df_group[metric_column]\n",
    "    \n",
    "    # Create a bar chart\n",
    "    sns.barplot(data=df_group, x='CTX_limit', y='Metric Value', hue='retrieval method', ax=ax, palette= \"inferno\")\n",
    "    \n",
    "    # Setting the title and labels\n",
    "    ax.set_title(f'{subject.capitalize()} - {survey_type}')\n",
    "    ax.set_xlabel('CTX Limit')\n",
    "    ax.set_ylabel('Metric Value')\n",
    "\n",
    "# Adjust layout for better readability\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Drop rows where SUBJECT == \"airidas\"\n",
    "# dfg = dfg[dfg['SUBJECT'] != \"airidas\"]\n",
    "# Compute summary statistics for each retrieval method\n",
    "summary_stats = dfg.groupby('retrieval method')[['p-corr_Elias_mean', 'mean_residual_Elias_std']].agg(['mean', 'var', 'std'])\n",
    "# Reset the multi-index to make the column labels more readable\n",
    "summary_stats.columns = ['_'.join(col).strip() for col in summary_stats.columns.values]\n",
    "summary_stats = summary_stats.reset_index()\n",
    "# Store the summary statistics in a DataFrame\n",
    "pd.DataFrame(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemMsg( \"You are participating in a survey. You will be presented with a series of questions about your video game preferrences.\", f\"You must choose answer to the question below with one of the five options: {', '.join(surv.POSSIBLE_ANSWERS)}. The answer must only contain the chosen option. \" ), \n",
    "# Understanding affirmation \n",
    "assistantMsg('Understood. I will answer the question below with one of the given options.'), \n",
    "# Survey question. With Simulation \n",
    "userMsg( question, \"Your choice: \" ),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "systemMsg(\"\\\\n\".join([\n",
    "            f\"You are an expert actor, specializing in impersonation of non-famouns people. You will be presented to the subject through explicit datapoints of their digital footprint. In addition, you will deduct their implicit {SURVEY} by shadowing chats between the subject and friends. You will be asked to fully immerse yourself in the role, and answer questions from the point of view of the persona. \\\\n#Context \\\\n##Chat conversations between the subject and their friends:\\\\n**From most to least related**\\\\n\",\n",
    "            \"\\\\n\\\\nNEW CONVERSATION:\\\\n\".join(chunks_most_similar)\n",
    "        ])),      \n",
    "        assistantMsg(\"Understood. I will answer from the point of view of the persona, based on what I could the deduct from the text provided.\"),\n",
    "        userMsg(\"\\\\n\".join([\n",
    "            f\"Persona is questioned about their {SURVEY} in an {METHOD}. The persona must choose an appropriate answer to the question below with one of these five given options: {', '.join(surv.POSSIBLE_ANSWERS)}. Persona's answer must only contain the chosen option, without any elaboration, nor introduction.\\\\n\\\\n**Your question is:**\\\\n\",\n",
    "            question,\n",
    "            \"\\\\nThe persona chooses:\"\n",
    "        ]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airi vs Eli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surv_kano = survey.KanoSurvey()\n",
    "surv_pers = survey.PersonalitySurvey()\n",
    "\n",
    "surv_kano.df = remap_answers_to_integers(surv_kano.df, surv_kano, remap_answer=False)\n",
    "surv_pers.df = remap_answers_to_integers(surv_pers.df, surv_pers, remap_answer=False)\n",
    "\n",
    "print(f\"Kano {utils.calc_MAE(surv_kano.df[\"airidas\"], surv_kano.df[\"elias\"])}\")\n",
    "print(f\"Pers {utils.calc_MAE(surv_pers.df[\"airidas\"], surv_pers.df[\"elias\"])}\")\n",
    "# now calc pearson correlation\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "# get correlation\n",
    "corr, _ = pearsonr(surv_kano.df[\"airidas\"], surv_kano.df[\"elias\"])\n",
    "print(f'Pearsons correlation Kano: {corr}')\n",
    "corr, _ = pearsonr(surv_pers.df[\"airidas\"], surv_pers.df[\"elias\"])\n",
    "print(f'Pearsons correlation Pers: {corr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_base_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'mean_residual_Airidas_mean' and 'p-corr_Airidas_mean' are already computed as mean values in your aggregated dataframe\n",
    "# Plotting for Airidas\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(dfg['p-corr_Airidas_mean'], dfg['MAE_airi_mean'], label='Airidas', alpha=0.5)\n",
    "\n",
    "# Assuming 'mean_residual_Elias_mean' and 'p-corr_Elias_mean' are also computed as mean values\n",
    "# Plotting for Elias\n",
    "plt.scatter(dfg['p-corr_Elias_mean'], dfg['MAE_eli_mean'], color='red', label='Elias', alpha=0.5)\n",
    "\n",
    "plt.title('Mean Residuals vs P-Corr')\n",
    "plt.xlabel('P-Corr (mean)')\n",
    "plt.ylabel('Mean Residuals (mean)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from scipy.integrate import quad\n",
    "\n",
    "# Parameters for the normal distribution\n",
    "mu = 2  # example mean\n",
    "sigma = 1  # example standard deviation\n",
    "\n",
    "# Define the integrand function\n",
    "def integrand(x):\n",
    "    return np.abs(x - 2) * norm.pdf(x, mu, sigma)\n",
    "\n",
    "# Compute the integral\n",
    "result, _ = quad(integrand, -np.inf, np.inf)\n",
    "print(\"Mean Absolute Error:\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mu, n = 2, 100000\n",
    "sigma = np.sqrt(0.9)\n",
    "np.random.seed(0)\n",
    "data = np.random.normal(mu, sigma, n)\n",
    "data_rounded = np.round(data).clip(0, 4)\n",
    "plt.figure(figsize=(4, 3))\n",
    "plt.hist(data_rounded, bins=np.arange(6) - 0.5, edgecolor='black', color='skyblue')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(range(5))\n",
    "stats_text = f\"Mean: {np.mean(data_rounded)}\\nMedian: {np.median(data_rounded)}\\nMin: {np.min(data_rounded)}\\nMax: {np.max(data_rounded)}\\nUnique Values: {len(np.unique(data_rounded))}\"\n",
    "guess = 2\n",
    "mae = np.mean(np.abs(data_rounded - guess))\n",
    "stats_text += f\"\\nMean Absolute Error (MAE) when always guessing {guess}: {mae}\"\n",
    "plt.text(5, plt.ylim()[1] * 0.95, stats_text, fontsize=8, verticalalignment='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = dfg[dfg[\"CTX_limit\"] == \"4000\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average\n",
    "average_value = dff[\"avg_tokens_in_prompt\"].mean()\n",
    "\n",
    "# Calculate minimum\n",
    "min_value = dff[\"avg_tokens_in_prompt\"].min()\n",
    "\n",
    "# Calculate maximum\n",
    "max_value = dff[\"avg_tokens_in_prompt\"].max()\n",
    "\n",
    "# Printing the results\n",
    "print(\"Average:\", average_value)\n",
    "print(\"Minimum:\", min_value)\n",
    "print(\"Maximum:\", max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey.KanoSurvey().df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
